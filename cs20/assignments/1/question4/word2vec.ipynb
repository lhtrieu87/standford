{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./enwik9_cleaned.txt\"\n",
    "vocabulary_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, errors='replace') as fin:\n",
    "        for line in fin:\n",
    "            yield line.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words()).most_common(n_words - 1))\n",
    "    \n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words():\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 3790053], ('the', 6473971), ('of', 3695441), ('and', 2502325), ('in', 2081782)]\n",
      "Sample data [19649, 7677, 0, 0, 0, 14049, 13031, 13031, 2966, 11] ['aaa', 'algeria', 'UNK', 'UNK', 'UNK', 'ada', 'anarchism', 'anarchism', 'originated', 'as']\n"
     ]
    }
   ],
   "source": [
    "data, count, dictionary, reverse_dictionary = build_dataset(\n",
    "    lambda: read_data(filename), vocabulary_size)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(index_words, window_size):\n",
    "    print(\"Generating samples...\")\n",
    "    while True:\n",
    "        for index, center in enumerate(index_words):\n",
    "            context_window_size = random.randint(1, window_size)\n",
    "\n",
    "            for target in index_words[max(0, index - context_window_size):index]:\n",
    "                yield center, target\n",
    "\n",
    "            for target in index_words[index + 1:min(len(index_words), index + context_window_size + 1)]:\n",
    "                yield center, target\n",
    "        print(\"Completed sampling one full round of data\")\n",
    "    print(\"Done with generating samples!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(index_words, batch_size, window_size):\n",
    "    sample_iter = sample(index_words, window_size)\n",
    "    \n",
    "    print(\"Generating batches...\")\n",
    "    while True:\n",
    "        center_batch = np.zeros((batch_size), dtype=np.int32)\n",
    "        target_batch = np.zeros((batch_size, 1), dtype=np.int32)\n",
    "        \n",
    "        for index in range(batch_size):\n",
    "            center_batch[index], target_batch[index] = next(sample_iter)\n",
    "            \n",
    "        yield center_batch, target_batch\n",
    "    \n",
    "    print(\"Done with generating batches!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128\n",
    "skip_window = 10\n",
    "num_sampled = 64\n",
    "learning_rate = 1.0\n",
    "num_train_steps = 3863999\n",
    "log_folder = \"processed/\"\n",
    "skip_step = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramModel:\n",
    "    def __init__(self, vocab_size, embed_size, batch_size, num_sampled, learning_rate):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_sampled = num_sampled\n",
    "        self.lr = learning_rate\n",
    "        self.global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name=\"global_step\")\n",
    "        \n",
    "    def _create_placeholders(self):\n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            self.center_words = tf.placeholder(tf.int32, shape=[self.batch_size], name=\"center_words\")\n",
    "            self.target_words = tf.placeholder(tf.int32, shape=[self.batch_size, 1], name=\"target_words\")\n",
    "\n",
    "    def _create_embedding(self):\n",
    "        with tf.name_scope(\"embed\"):\n",
    "            self.embed_matrix = tf.Variable(tf.random_uniform([self.vocab_size, self.embed_size], -1.0, 1.0),\n",
    "                                            name=\"embed_matrix\")\n",
    "            \n",
    "    def _create_loss(self):\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            embed = tf.nn.embedding_lookup(self.embed_matrix, self.center_words, name=\"embed\")\n",
    "            \n",
    "            nce_weight = tf.Variable(tf.truncated_normal([self.vocab_size, self.embed_size],\n",
    "                                                         stddev=1.0 / (self.embed_size ** 0.5)),\n",
    "                                     name=\"nce_weight\")\n",
    "            nce_bias = tf.Variable(tf.zeros([self.vocab_size]), name=\"nce_bias\")\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weight, \n",
    "                                                      biases=nce_bias, \n",
    "                                                      labels=self.target_words, \n",
    "                                                      inputs=embed, \n",
    "                                                      num_sampled=self.num_sampled,\n",
    "                                                      num_classes=self.vocab_size),\n",
    "                                       name=\"loss\")\n",
    "            \n",
    "    def _create_optimizer(self):\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss,\n",
    "                                                                             global_step=self.global_step)\n",
    "        \n",
    "    \n",
    "    def _create_summaries(self):\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            tf.summary.scalar(\"loss\", self.loss)\n",
    "            tf.summary.histogram(\"histogram_loss\", self.loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "            \n",
    "            \n",
    "    def build_graph(self):\n",
    "        self._create_placeholders()\n",
    "        self._create_embedding()\n",
    "        self._create_loss()\n",
    "        self._create_optimizer()\n",
    "        self._create_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_gen, num_train_steps, weights_fld, skip_step=skip_step, lr=learning_rate):\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    initial_step = 0\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print(\"Global variables initializing...\")\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # If a checkpoint exists, restore from the checkpoint.\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname(\"checkpoints/checkpoint\"))\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "        total_loss = 0.0\n",
    "        \n",
    "        writer = tf.summary.FileWriter('improved_graph/lr' + str(lr), sess.graph)\n",
    "        initial_step = model.global_step.eval()    \n",
    "        \n",
    "        print(\"Start training...\")\n",
    "        for index in range(initial_step, initial_step + num_train_steps):    \n",
    "            centers, targets = next(batch_gen)\n",
    "            feed_dict = {\n",
    "                model.center_words: centers,\n",
    "                model.target_words: targets,\n",
    "            }\n",
    "            loss_batch, _, summary = sess.run([model.loss, model.optimizer, model.summary_op],\n",
    "                                             feed_dict=feed_dict)\n",
    "            writer.add_summary(summary, global_step=index)\n",
    "            total_loss += loss_batch\n",
    "            if(index + 1) % skip_step == 0:\n",
    "                print('Average loss at step {}: {:5.1f}'.format(index, total_loss / skip_step))\n",
    "                total_loss = 0.0\n",
    "                saver.save(sess, 'checkpoints/checkpoint', index)\n",
    "                \n",
    "        final_embed_matrix = sess.run(model.embed_matrix)\n",
    "        \n",
    "        # it has to variable. constants don't work here. you can't reuse model.embed_matrix\n",
    "        embedding_var = tf.Variable(final_embed_matrix, name='embedding')\n",
    "        sess.run(embedding_var.initializer)\n",
    "\n",
    "        config = projector.ProjectorConfig()\n",
    "        summary_writer = tf.summary.FileWriter('processed')\n",
    "\n",
    "        # add embedding to the config file\n",
    "        embedding = config.embeddings.add()\n",
    "        embedding.tensor_name = embedding_var.name\n",
    "        \n",
    "        # link this tensor to its metadata file, in this case the first 500 words of vocab\n",
    "        embedding.metadata_path = 'vocab.tsv'\n",
    "\n",
    "        # saves a configuration file that TensorBoard will read during startup.\n",
    "        projector.visualize_embeddings(summary_writer, config)\n",
    "        saver_embed = tf.train.Saver([embedding_var])\n",
    "        saver_embed.save(sess, 'processed/model3.ckpt', 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('processed/vocab.tsv', \"wb\") as f:\n",
    "    for v in dictionary:\n",
    "        f.write(v.encode('utf-8') + b'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global variables initializing...\n",
      "Start training...\n",
      "Generating batches...\n",
      "Generating samples...\n",
      "Average loss at step 1999: 118.9\n",
      "Average loss at step 3999:  59.9\n",
      "Average loss at step 5999:  38.2\n",
      "Average loss at step 7999:  30.0\n",
      "Average loss at step 9999:  23.1\n",
      "Average loss at step 11999:  18.9\n",
      "Average loss at step 13999:  16.6\n",
      "Average loss at step 15999:  15.1\n",
      "Average loss at step 17999:  12.7\n",
      "Average loss at step 19999:  12.1\n",
      "Average loss at step 21999:  11.7\n",
      "Average loss at step 23999:  11.7\n",
      "Average loss at step 25999:  10.0\n",
      "Average loss at step 27999:  10.5\n",
      "Average loss at step 29999:   9.4\n",
      "Average loss at step 31999:   9.5\n",
      "Average loss at step 33999:   9.4\n",
      "Average loss at step 35999:   8.8\n",
      "Average loss at step 37999:   9.2\n",
      "Average loss at step 39999:   8.6\n",
      "Average loss at step 41999:   8.6\n",
      "Average loss at step 43999:   7.7\n",
      "Average loss at step 45999:   8.0\n",
      "Average loss at step 47999:   7.9\n",
      "Average loss at step 49999:   7.7\n",
      "Average loss at step 51999:   7.8\n",
      "Average loss at step 53999:   7.6\n",
      "Average loss at step 55999:   7.4\n",
      "Average loss at step 57999:   7.5\n",
      "Average loss at step 59999:   7.5\n",
      "Average loss at step 61999:   7.2\n",
      "Average loss at step 63999:   7.3\n",
      "Average loss at step 65999:   7.1\n",
      "Average loss at step 67999:   7.1\n",
      "Average loss at step 69999:   6.8\n",
      "Average loss at step 71999:   6.7\n",
      "Average loss at step 73999:   7.4\n",
      "Average loss at step 75999:   7.0\n",
      "Average loss at step 77999:   7.1\n",
      "Average loss at step 79999:   6.7\n",
      "Average loss at step 81999:   6.7\n",
      "Average loss at step 83999:   6.6\n",
      "Average loss at step 85999:   6.5\n",
      "Average loss at step 87999:   6.6\n",
      "Average loss at step 89999:   6.6\n",
      "Average loss at step 91999:   6.3\n",
      "Average loss at step 93999:   6.6\n",
      "Average loss at step 95999:   6.4\n",
      "Average loss at step 97999:   6.5\n",
      "Average loss at step 99999:   6.6\n",
      "Average loss at step 101999:   6.7\n",
      "Average loss at step 103999:   6.3\n",
      "Average loss at step 105999:   6.1\n",
      "Average loss at step 107999:   6.6\n",
      "Average loss at step 109999:   6.3\n",
      "Average loss at step 111999:   5.7\n",
      "Average loss at step 113999:   5.9\n",
      "Average loss at step 115999:   6.3\n",
      "Average loss at step 117999:   6.4\n",
      "Average loss at step 119999:   6.2\n",
      "Average loss at step 121999:   6.3\n",
      "Average loss at step 123999:   5.8\n",
      "Average loss at step 125999:   6.0\n",
      "Average loss at step 127999:   6.4\n",
      "Average loss at step 129999:   6.0\n",
      "Average loss at step 131999:   6.4\n",
      "Average loss at step 133999:   5.9\n",
      "Average loss at step 135999:   5.9\n",
      "Average loss at step 137999:   6.1\n",
      "Average loss at step 139999:   6.4\n",
      "Average loss at step 141999:   6.0\n",
      "Average loss at step 143999:   6.0\n",
      "Average loss at step 145999:   5.8\n",
      "Average loss at step 147999:   6.0\n",
      "Average loss at step 149999:   5.8\n",
      "Average loss at step 151999:   5.7\n",
      "Average loss at step 153999:   5.6\n",
      "Average loss at step 155999:   7.0\n",
      "Average loss at step 157999:   5.9\n",
      "Average loss at step 159999:   5.9\n",
      "Average loss at step 161999:   5.9\n",
      "Average loss at step 163999:   5.6\n",
      "Average loss at step 165999:   5.7\n",
      "Average loss at step 167999:   5.8\n",
      "Average loss at step 169999:   5.8\n",
      "Average loss at step 171999:   5.6\n",
      "Average loss at step 173999:   5.5\n",
      "Average loss at step 175999:   5.7\n",
      "Average loss at step 177999:   5.8\n",
      "Average loss at step 179999:   5.6\n",
      "Average loss at step 181999:   5.5\n",
      "Average loss at step 183999:   5.5\n",
      "Average loss at step 185999:   5.7\n",
      "Average loss at step 187999:   5.6\n",
      "Average loss at step 189999:   5.7\n",
      "Average loss at step 191999:   5.6\n",
      "Average loss at step 193999:   5.5\n",
      "Average loss at step 195999:   5.4\n",
      "Average loss at step 197999:   5.4\n",
      "Average loss at step 199999:   5.6\n",
      "Average loss at step 201999:   5.3\n",
      "Average loss at step 203999:   5.7\n",
      "Average loss at step 205999:   5.3\n",
      "Average loss at step 207999:   5.3\n",
      "Average loss at step 209999:   5.7\n",
      "Average loss at step 211999:   5.5\n",
      "Average loss at step 213999:   5.5\n",
      "Average loss at step 215999:   5.5\n",
      "Average loss at step 217999:   5.4\n",
      "Average loss at step 219999:   5.3\n",
      "Average loss at step 221999:   5.4\n",
      "Average loss at step 223999:   5.5\n",
      "Average loss at step 225999:   5.5\n",
      "Average loss at step 227999:   5.4\n",
      "Average loss at step 229999:   5.4\n",
      "Average loss at step 231999:   5.5\n",
      "Average loss at step 233999:   5.5\n",
      "Average loss at step 235999:   5.5\n",
      "Average loss at step 237999:   5.6\n",
      "Average loss at step 239999:   5.2\n",
      "Average loss at step 241999:   5.3\n",
      "Average loss at step 243999:   5.3\n",
      "Average loss at step 245999:   5.2\n",
      "Average loss at step 247999:   5.3\n",
      "Average loss at step 249999:   5.2\n",
      "Average loss at step 251999:   5.3\n",
      "Average loss at step 253999:   5.2\n",
      "Average loss at step 255999:   5.3\n",
      "Average loss at step 257999:   5.2\n",
      "Average loss at step 259999:   5.1\n",
      "Average loss at step 261999:   5.3\n",
      "Average loss at step 263999:   5.2\n",
      "Average loss at step 265999:   5.2\n",
      "Average loss at step 267999:   5.3\n",
      "Average loss at step 269999:   5.4\n",
      "Average loss at step 271999:   5.2\n",
      "Average loss at step 273999:   5.4\n",
      "Average loss at step 275999:   5.3\n",
      "Average loss at step 277999:   5.3\n",
      "Average loss at step 279999:   5.3\n",
      "Average loss at step 281999:   5.3\n",
      "Average loss at step 283999:   6.4\n",
      "Average loss at step 285999:   5.3\n",
      "Average loss at step 287999:   5.1\n",
      "Average loss at step 289999:   5.2\n",
      "Average loss at step 291999:   5.3\n",
      "Average loss at step 293999:   5.1\n",
      "Average loss at step 295999:   5.1\n",
      "Average loss at step 297999:   5.2\n",
      "Average loss at step 299999:   5.2\n",
      "Average loss at step 301999:   5.1\n",
      "Average loss at step 303999:   5.2\n",
      "Average loss at step 305999:   5.2\n",
      "Average loss at step 307999:   5.2\n",
      "Average loss at step 309999:   5.2\n",
      "Average loss at step 311999:   5.3\n",
      "Average loss at step 313999:   5.0\n",
      "Average loss at step 315999:   5.3\n",
      "Average loss at step 317999:   5.0\n",
      "Average loss at step 319999:   5.1\n",
      "Average loss at step 321999:   5.2\n",
      "Average loss at step 323999:   5.2\n",
      "Average loss at step 325999:   5.1\n",
      "Average loss at step 327999:   5.3\n",
      "Average loss at step 329999:   5.2\n",
      "Average loss at step 331999:   5.2\n",
      "Average loss at step 333999:   5.1\n",
      "Average loss at step 335999:   5.2\n",
      "Average loss at step 337999:   5.2\n",
      "Average loss at step 339999:   5.3\n",
      "Average loss at step 341999:   5.2\n",
      "Average loss at step 343999:   5.1\n",
      "Average loss at step 345999:   5.2\n",
      "Average loss at step 347999:   5.1\n",
      "Average loss at step 349999:   5.2\n",
      "Average loss at step 351999:   5.2\n",
      "Average loss at step 353999:   5.2\n",
      "Average loss at step 355999:   5.1\n",
      "Average loss at step 357999:   5.2\n",
      "Average loss at step 359999:   5.0\n",
      "Average loss at step 361999:   5.0\n",
      "Average loss at step 363999:   5.2\n",
      "Average loss at step 365999:   5.0\n",
      "Average loss at step 367999:   5.0\n",
      "Average loss at step 369999:   5.0\n",
      "Average loss at step 371999:   5.0\n",
      "Average loss at step 373999:   5.1\n",
      "Average loss at step 375999:   5.2\n",
      "Average loss at step 377999:   5.0\n",
      "Average loss at step 379999:   5.3\n",
      "Average loss at step 381999:   5.1\n",
      "Average loss at step 383999:   5.2\n",
      "Average loss at step 385999:   5.1\n",
      "Average loss at step 387999:   5.2\n",
      "Average loss at step 389999:   5.0\n",
      "Average loss at step 391999:   5.0\n",
      "Average loss at step 393999:   5.0\n",
      "Average loss at step 395999:   5.1\n",
      "Average loss at step 397999:   5.1\n",
      "Average loss at step 399999:   5.2\n",
      "Average loss at step 401999:   5.2\n",
      "Average loss at step 403999:   5.1\n",
      "Average loss at step 405999:   5.1\n",
      "Average loss at step 407999:   5.0\n",
      "Average loss at step 409999:   5.1\n",
      "Average loss at step 411999:   5.0\n",
      "Average loss at step 413999:   5.1\n",
      "Average loss at step 415999:   5.1\n",
      "Average loss at step 417999:   5.1\n",
      "Average loss at step 419999:   5.1\n",
      "Average loss at step 421999:   5.0\n",
      "Average loss at step 423999:   5.1\n",
      "Average loss at step 425999:   5.2\n",
      "Average loss at step 427999:   5.0\n",
      "Average loss at step 429999:   5.2\n",
      "Average loss at step 431999:   5.1\n",
      "Average loss at step 433999:   5.2\n",
      "Average loss at step 435999:   5.0\n",
      "Average loss at step 437999:   5.1\n",
      "Average loss at step 439999:   5.1\n",
      "Average loss at step 441999:   5.1\n",
      "Average loss at step 443999:   5.1\n",
      "Average loss at step 445999:   5.1\n",
      "Average loss at step 447999:   5.0\n",
      "Average loss at step 449999:   5.2\n",
      "Average loss at step 451999:   5.0\n",
      "Average loss at step 453999:   4.9\n",
      "Average loss at step 455999:   4.9\n",
      "Average loss at step 457999:   5.0\n",
      "Average loss at step 459999:   5.0\n",
      "Average loss at step 461999:   4.9\n",
      "Average loss at step 463999:   4.9\n",
      "Average loss at step 465999:   4.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 467999:   5.1\n",
      "Average loss at step 469999:   4.9\n",
      "Average loss at step 471999:   5.1\n",
      "Average loss at step 473999:   5.0\n",
      "Average loss at step 475999:   4.9\n",
      "Average loss at step 477999:   5.1\n",
      "Average loss at step 479999:   5.0\n",
      "Average loss at step 481999:   5.0\n",
      "Average loss at step 483999:   5.0\n",
      "Average loss at step 485999:   4.9\n",
      "Average loss at step 487999:   5.1\n",
      "Average loss at step 489999:   4.9\n",
      "Average loss at step 491999:   5.0\n",
      "Average loss at step 493999:   4.9\n",
      "Average loss at step 495999:   5.0\n",
      "Average loss at step 497999:   5.1\n",
      "Average loss at step 499999:   5.1\n",
      "Average loss at step 501999:   5.0\n",
      "Average loss at step 503999:   5.1\n",
      "Average loss at step 505999:   4.9\n",
      "Average loss at step 507999:   4.9\n",
      "Average loss at step 509999:   5.0\n",
      "Average loss at step 511999:   5.1\n",
      "Average loss at step 513999:   5.0\n",
      "Average loss at step 515999:   4.9\n",
      "Average loss at step 517999:   4.8\n",
      "Average loss at step 519999:   5.0\n",
      "Average loss at step 521999:   5.0\n",
      "Average loss at step 523999:   5.0\n",
      "Average loss at step 525999:   4.9\n",
      "Average loss at step 527999:   5.0\n",
      "Average loss at step 529999:   4.8\n",
      "Average loss at step 531999:   5.0\n",
      "Average loss at step 533999:   5.0\n",
      "Average loss at step 535999:   5.0\n",
      "Average loss at step 537999:   5.0\n",
      "Average loss at step 539999:   4.8\n",
      "Average loss at step 541999:   4.8\n",
      "Average loss at step 543999:   5.0\n",
      "Average loss at step 545999:   4.8\n",
      "Average loss at step 547999:   5.0\n",
      "Average loss at step 549999:   4.9\n",
      "Average loss at step 551999:   5.0\n",
      "Average loss at step 553999:   5.1\n",
      "Average loss at step 555999:   4.9\n",
      "Average loss at step 557999:   5.1\n",
      "Average loss at step 559999:   5.0\n",
      "Average loss at step 561999:   4.9\n",
      "Average loss at step 563999:   4.0\n",
      "Average loss at step 565999:   3.8\n",
      "Average loss at step 567999:   4.9\n",
      "Average loss at step 569999:   4.9\n",
      "Average loss at step 571999:   5.0\n",
      "Average loss at step 573999:   5.1\n",
      "Average loss at step 575999:   4.9\n",
      "Average loss at step 577999:   4.9\n",
      "Average loss at step 579999:   5.0\n",
      "Average loss at step 581999:   4.9\n",
      "Average loss at step 583999:   5.0\n",
      "Average loss at step 585999:   5.0\n",
      "Average loss at step 587999:   5.0\n",
      "Average loss at step 589999:   4.9\n",
      "Average loss at step 591999:   4.8\n",
      "Average loss at step 593999:   5.0\n",
      "Average loss at step 595999:   5.0\n",
      "Average loss at step 597999:   4.9\n",
      "Average loss at step 599999:   4.8\n",
      "Average loss at step 601999:   5.0\n",
      "Average loss at step 603999:   4.7\n",
      "Average loss at step 605999:   4.8\n",
      "Average loss at step 607999:   5.0\n",
      "Average loss at step 609999:   5.0\n",
      "Average loss at step 611999:   5.0\n",
      "Average loss at step 613999:   4.9\n",
      "Average loss at step 615999:   4.9\n",
      "Average loss at step 617999:   4.8\n",
      "Average loss at step 619999:   5.0\n",
      "Average loss at step 621999:   4.9\n",
      "Average loss at step 623999:   4.9\n",
      "Average loss at step 625999:   4.9\n",
      "Average loss at step 627999:   4.9\n",
      "Average loss at step 629999:   5.0\n",
      "Average loss at step 631999:   4.9\n",
      "Average loss at step 633999:   5.0\n",
      "Average loss at step 635999:   5.1\n",
      "Average loss at step 637999:   6.9\n",
      "Average loss at step 639999:   5.1\n",
      "Average loss at step 641999:   4.9\n",
      "Average loss at step 643999:   5.0\n",
      "Average loss at step 645999:   5.1\n",
      "Average loss at step 647999:   5.0\n",
      "Average loss at step 649999:   5.0\n",
      "Average loss at step 651999:   5.1\n",
      "Average loss at step 653999:   5.0\n",
      "Average loss at step 655999:   4.9\n",
      "Average loss at step 657999:   4.9\n",
      "Average loss at step 659999:   4.9\n",
      "Average loss at step 661999:   4.9\n",
      "Average loss at step 663999:   4.8\n",
      "Average loss at step 665999:   5.4\n",
      "Average loss at step 667999:   5.0\n",
      "Average loss at step 669999:   5.0\n",
      "Average loss at step 671999:   4.9\n",
      "Average loss at step 673999:   4.9\n",
      "Average loss at step 675999:   4.9\n",
      "Average loss at step 677999:   4.9\n",
      "Average loss at step 679999:   4.9\n",
      "Average loss at step 681999:   4.9\n",
      "Average loss at step 683999:   4.8\n",
      "Average loss at step 685999:   4.9\n",
      "Average loss at step 687999:   5.0\n",
      "Average loss at step 689999:   5.0\n",
      "Average loss at step 691999:   4.9\n",
      "Average loss at step 693999:   4.8\n",
      "Average loss at step 695999:   4.8\n",
      "Average loss at step 697999:   4.8\n",
      "Average loss at step 699999:   4.9\n",
      "Average loss at step 701999:   4.9\n",
      "Average loss at step 703999:   5.0\n",
      "Average loss at step 705999:   5.0\n",
      "Average loss at step 707999:   4.8\n",
      "Average loss at step 709999:   5.0\n",
      "Average loss at step 711999:   5.0\n",
      "Average loss at step 713999:   4.9\n",
      "Average loss at step 715999:   4.9\n",
      "Average loss at step 717999:   4.8\n",
      "Average loss at step 719999:   4.9\n",
      "Average loss at step 721999:   4.8\n",
      "Average loss at step 723999:   4.9\n",
      "Average loss at step 725999:   5.0\n",
      "Average loss at step 727999:   4.9\n",
      "Average loss at step 729999:   4.7\n",
      "Average loss at step 731999:   4.9\n",
      "Average loss at step 733999:   4.9\n",
      "Average loss at step 735999:   4.8\n",
      "Average loss at step 737999:   5.0\n",
      "Average loss at step 739999:   4.8\n",
      "Average loss at step 741999:   4.9\n",
      "Average loss at step 743999:   4.8\n",
      "Average loss at step 745999:   4.8\n",
      "Average loss at step 747999:   4.7\n",
      "Average loss at step 749999:   4.8\n",
      "Average loss at step 751999:   4.8\n",
      "Average loss at step 753999:   4.9\n",
      "Average loss at step 755999:   4.8\n",
      "Average loss at step 757999:   4.8\n",
      "Average loss at step 759999:   4.8\n",
      "Average loss at step 761999:   4.8\n",
      "Average loss at step 763999:   4.8\n",
      "Average loss at step 765999:   4.9\n",
      "Average loss at step 767999:   4.8\n",
      "Average loss at step 769999:   4.8\n",
      "Average loss at step 771999:   4.9\n",
      "Average loss at step 773999:   4.8\n",
      "Average loss at step 775999:   4.8\n",
      "Average loss at step 777999:   4.8\n",
      "Average loss at step 779999:   4.8\n",
      "Average loss at step 781999:   4.8\n",
      "Average loss at step 783999:   4.8\n",
      "Average loss at step 785999:   4.9\n",
      "Average loss at step 787999:   4.8\n",
      "Average loss at step 789999:   4.6\n",
      "Average loss at step 791999:   5.0\n",
      "Average loss at step 793999:   4.9\n",
      "Average loss at step 795999:   4.9\n",
      "Average loss at step 797999:   5.0\n",
      "Average loss at step 799999:   4.8\n",
      "Average loss at step 801999:   4.8\n",
      "Average loss at step 803999:   4.9\n",
      "Average loss at step 805999:   4.9\n",
      "Average loss at step 807999:   4.9\n",
      "Average loss at step 809999:   5.0\n",
      "Average loss at step 811999:   4.9\n",
      "Average loss at step 813999:   4.9\n",
      "Average loss at step 815999:   4.9\n",
      "Average loss at step 817999:   4.9\n",
      "Average loss at step 819999:   4.9\n",
      "Average loss at step 821999:   4.9\n",
      "Average loss at step 823999:   4.8\n",
      "Average loss at step 825999:   5.0\n",
      "Average loss at step 827999:   5.0\n",
      "Average loss at step 829999:   4.9\n",
      "Average loss at step 831999:   4.9\n",
      "Average loss at step 833999:   4.9\n",
      "Average loss at step 835999:   4.9\n",
      "Average loss at step 837999:   4.9\n",
      "Average loss at step 839999:   4.9\n",
      "Average loss at step 841999:   4.9\n",
      "Average loss at step 843999:   4.9\n",
      "Average loss at step 845999:   4.9\n",
      "Average loss at step 847999:   4.8\n",
      "Average loss at step 849999:   4.7\n",
      "Average loss at step 851999:   4.8\n",
      "Average loss at step 853999:   4.8\n",
      "Average loss at step 855999:   4.8\n",
      "Average loss at step 857999:   4.9\n",
      "Average loss at step 859999:   4.9\n",
      "Average loss at step 861999:   4.8\n",
      "Average loss at step 863999:   4.9\n",
      "Average loss at step 865999:   4.9\n",
      "Average loss at step 867999:   5.0\n",
      "Average loss at step 869999:   4.9\n",
      "Average loss at step 871999:   4.9\n",
      "Average loss at step 873999:   4.9\n",
      "Average loss at step 875999:   4.9\n",
      "Average loss at step 877999:   4.9\n",
      "Average loss at step 879999:   4.9\n",
      "Average loss at step 881999:   4.9\n",
      "Average loss at step 883999:   4.7\n",
      "Average loss at step 885999:   4.8\n",
      "Average loss at step 887999:   4.8\n",
      "Average loss at step 889999:   4.8\n",
      "Average loss at step 891999:   4.8\n",
      "Average loss at step 893999:   4.8\n",
      "Average loss at step 895999:   4.6\n",
      "Average loss at step 897999:   4.5\n",
      "Average loss at step 899999:   5.5\n",
      "Average loss at step 901999:   5.0\n",
      "Average loss at step 903999:   4.8\n",
      "Average loss at step 905999:   4.9\n",
      "Average loss at step 907999:   4.8\n",
      "Average loss at step 909999:   4.8\n",
      "Average loss at step 911999:   4.8\n",
      "Average loss at step 913999:   4.9\n",
      "Average loss at step 915999:   5.0\n",
      "Average loss at step 917999:   4.9\n",
      "Average loss at step 919999:   4.8\n",
      "Average loss at step 921999:   4.8\n",
      "Average loss at step 923999:   5.0\n",
      "Average loss at step 925999:   4.9\n",
      "Average loss at step 927999:   4.9\n",
      "Average loss at step 929999:   4.9\n",
      "Average loss at step 931999:   4.9\n",
      "Average loss at step 933999:   4.8\n",
      "Average loss at step 935999:   4.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 937999:   4.9\n",
      "Average loss at step 939999:   4.9\n",
      "Average loss at step 941999:   4.9\n",
      "Average loss at step 943999:   4.9\n",
      "Average loss at step 945999:   4.8\n",
      "Average loss at step 947999:   4.8\n",
      "Average loss at step 949999:   4.8\n",
      "Average loss at step 951999:   4.8\n",
      "Average loss at step 953999:   4.8\n",
      "Average loss at step 955999:   4.9\n",
      "Average loss at step 957999:   4.8\n",
      "Average loss at step 959999:   4.8\n",
      "Average loss at step 961999:   4.7\n",
      "Average loss at step 963999:   4.6\n",
      "Average loss at step 965999:   4.9\n",
      "Average loss at step 967999:   4.6\n",
      "Average loss at step 969999:   4.7\n",
      "Average loss at step 971999:   4.5\n",
      "Average loss at step 973999:   4.6\n",
      "Average loss at step 975999:   4.7\n",
      "Average loss at step 977999:   4.9\n",
      "Average loss at step 979999:   4.8\n",
      "Average loss at step 981999:   4.8\n",
      "Average loss at step 983999:   4.8\n",
      "Average loss at step 985999:   4.8\n",
      "Average loss at step 987999:   4.8\n",
      "Average loss at step 989999:   4.9\n",
      "Average loss at step 991999:   4.8\n",
      "Average loss at step 993999:   4.7\n",
      "Average loss at step 995999:   4.8\n",
      "Average loss at step 997999:   4.8\n",
      "Average loss at step 999999:   4.8\n",
      "Average loss at step 1001999:   4.8\n",
      "Average loss at step 1003999:   4.8\n",
      "Average loss at step 1005999:   4.8\n",
      "Average loss at step 1007999:   4.9\n",
      "Average loss at step 1009999:   4.8\n",
      "Average loss at step 1011999:   4.7\n",
      "Average loss at step 1013999:   4.9\n",
      "Average loss at step 1015999:   4.9\n",
      "Average loss at step 1017999:   4.8\n",
      "Average loss at step 1019999:   4.9\n",
      "Average loss at step 1021999:   4.9\n",
      "Average loss at step 1023999:   4.8\n",
      "Average loss at step 1025999:   4.8\n",
      "Average loss at step 1027999:   4.8\n",
      "Average loss at step 1029999:   4.8\n",
      "Average loss at step 1031999:   4.8\n",
      "Average loss at step 1033999:   4.8\n",
      "Average loss at step 1035999:   4.9\n",
      "Average loss at step 1037999:   4.9\n",
      "Average loss at step 1039999:   4.8\n",
      "Average loss at step 1041999:   4.8\n",
      "Average loss at step 1043999:   4.8\n",
      "Average loss at step 1045999:   4.8\n",
      "Average loss at step 1047999:   4.8\n",
      "Average loss at step 1049999:   4.9\n",
      "Average loss at step 1051999:   4.8\n",
      "Average loss at step 1053999:   4.9\n",
      "Average loss at step 1055999:   4.8\n",
      "Average loss at step 1057999:   4.9\n",
      "Average loss at step 1059999:   4.8\n",
      "Average loss at step 1061999:   4.9\n",
      "Average loss at step 1063999:   4.8\n",
      "Average loss at step 1065999:   4.8\n",
      "Average loss at step 1067999:   4.8\n",
      "Average loss at step 1069999:   4.8\n",
      "Average loss at step 1071999:   4.8\n",
      "Average loss at step 1073999:   4.6\n",
      "Average loss at step 1075999:   4.5\n",
      "Average loss at step 1077999:   4.5\n",
      "Average loss at step 1079999:   4.5\n",
      "Average loss at step 1081999:   4.7\n",
      "Average loss at step 1083999:   4.8\n",
      "Average loss at step 1085999:   4.7\n",
      "Average loss at step 1087999:   4.7\n",
      "Average loss at step 1089999:   4.9\n",
      "Average loss at step 1091999:   4.8\n",
      "Average loss at step 1093999:   4.8\n",
      "Average loss at step 1095999:   4.8\n",
      "Average loss at step 1097999:   4.6\n",
      "Average loss at step 1099999:   4.8\n",
      "Average loss at step 1101999:   4.6\n",
      "Average loss at step 1103999:   4.8\n",
      "Average loss at step 1105999:   4.8\n",
      "Average loss at step 1107999:   4.8\n",
      "Average loss at step 1109999:   4.8\n",
      "Average loss at step 1111999:   4.8\n",
      "Average loss at step 1113999:   4.8\n",
      "Average loss at step 1115999:   4.8\n",
      "Average loss at step 1117999:   4.8\n",
      "Average loss at step 1119999:   4.7\n",
      "Average loss at step 1121999:   4.6\n",
      "Average loss at step 1123999:   4.8\n",
      "Average loss at step 1125999:   4.8\n",
      "Average loss at step 1127999:   4.7\n",
      "Average loss at step 1129999:   4.7\n",
      "Average loss at step 1131999:   4.6\n",
      "Average loss at step 1133999:   4.8\n",
      "Average loss at step 1135999:   4.8\n",
      "Average loss at step 1137999:   4.9\n",
      "Average loss at step 1139999:   4.7\n",
      "Average loss at step 1141999:   4.8\n",
      "Average loss at step 1143999:   4.8\n",
      "Average loss at step 1145999:   4.7\n",
      "Average loss at step 1147999:   8.0\n",
      "Average loss at step 1149999:   5.6\n",
      "Average loss at step 1151999:   5.8\n",
      "Average loss at step 1153999:   5.1\n",
      "Average loss at step 1155999:   5.1\n",
      "Average loss at step 1157999:   5.1\n",
      "Average loss at step 1159999:   5.0\n",
      "Average loss at step 1161999:   5.0\n",
      "Average loss at step 1163999:   5.0\n",
      "Average loss at step 1165999:   4.6\n",
      "Average loss at step 1167999:   5.1\n",
      "Average loss at step 1169999:   5.0\n",
      "Average loss at step 1171999:   4.9\n",
      "Average loss at step 1173999:   4.9\n",
      "Average loss at step 1175999:   4.9\n",
      "Average loss at step 1177999:   5.0\n",
      "Average loss at step 1179999:   4.8\n",
      "Average loss at step 1181999:   4.7\n",
      "Average loss at step 1183999:   4.7\n",
      "Average loss at step 1185999:   4.8\n",
      "Average loss at step 1187999:   4.8\n",
      "Average loss at step 1189999:   4.9\n",
      "Average loss at step 1191999:   4.9\n",
      "Average loss at step 1193999:   4.8\n",
      "Average loss at step 1195999:   5.5\n",
      "Average loss at step 1197999:   4.8\n",
      "Average loss at step 1199999:   4.8\n",
      "Average loss at step 1201999:   4.8\n",
      "Average loss at step 1203999:   4.9\n",
      "Average loss at step 1205999:   4.9\n",
      "Average loss at step 1207999:   4.8\n",
      "Average loss at step 1209999:   4.9\n",
      "Average loss at step 1211999:   4.9\n",
      "Average loss at step 1213999:   4.9\n",
      "Average loss at step 1215999:   5.0\n",
      "Average loss at step 1217999:   4.9\n",
      "Average loss at step 1219999:   4.8\n",
      "Average loss at step 1221999:   4.8\n",
      "Average loss at step 1223999:   4.9\n",
      "Average loss at step 1225999:   5.1\n",
      "Average loss at step 1227999:   4.8\n",
      "Average loss at step 1229999:   4.8\n",
      "Average loss at step 1231999:   4.9\n",
      "Average loss at step 1233999:   4.9\n",
      "Average loss at step 1235999:   4.7\n",
      "Average loss at step 1237999:   4.8\n",
      "Average loss at step 1239999:   4.8\n",
      "Average loss at step 1241999:   4.8\n",
      "Average loss at step 1243999:   4.8\n",
      "Average loss at step 1245999:   4.8\n",
      "Average loss at step 1247999:   4.9\n",
      "Average loss at step 1249999:   4.8\n",
      "Average loss at step 1251999:   4.7\n",
      "Average loss at step 1253999:   4.7\n",
      "Average loss at step 1255999:   4.8\n",
      "Average loss at step 1257999:   4.8\n",
      "Average loss at step 1259999:   4.8\n",
      "Average loss at step 1261999:   4.8\n",
      "Average loss at step 1263999:   4.9\n",
      "Average loss at step 1265999:   4.8\n",
      "Average loss at step 1267999:   4.8\n",
      "Average loss at step 1269999:   4.9\n",
      "Average loss at step 1271999:   5.0\n",
      "Average loss at step 1273999:   4.6\n",
      "Average loss at step 1275999:   4.7\n",
      "Average loss at step 1277999:   4.7\n",
      "Average loss at step 1279999:   4.8\n",
      "Average loss at step 1281999:   4.7\n",
      "Average loss at step 1283999:   4.8\n",
      "Average loss at step 1285999:   4.9\n",
      "Average loss at step 1287999:   4.8\n",
      "Average loss at step 1289999:   4.9\n",
      "Average loss at step 1291999:   4.8\n",
      "Average loss at step 1293999:   4.7\n",
      "Average loss at step 1295999:   4.7\n",
      "Average loss at step 1297999:   4.7\n",
      "Average loss at step 1299999:   4.8\n",
      "Average loss at step 1301999:   4.7\n",
      "Average loss at step 1303999:   4.5\n",
      "Average loss at step 1305999:   4.7\n",
      "Average loss at step 1307999:   4.7\n",
      "Average loss at step 1309999:   4.8\n",
      "Average loss at step 1311999:   4.7\n",
      "Average loss at step 1313999:   4.8\n",
      "Average loss at step 1315999:   4.8\n",
      "Average loss at step 1317999:   4.8\n",
      "Average loss at step 1319999:   4.9\n",
      "Average loss at step 1321999:   4.7\n",
      "Average loss at step 1323999:   4.7\n",
      "Average loss at step 1325999:   4.8\n",
      "Average loss at step 1327999:   4.8\n",
      "Average loss at step 1329999:   4.8\n",
      "Average loss at step 1331999:   4.8\n",
      "Average loss at step 1333999:   4.8\n",
      "Average loss at step 1335999:   4.8\n",
      "Average loss at step 1337999:   4.8\n",
      "Average loss at step 1339999:   4.8\n",
      "Average loss at step 1341999:   4.7\n",
      "Average loss at step 1343999:   4.8\n",
      "Average loss at step 1345999:   4.7\n",
      "Average loss at step 1347999:   4.8\n",
      "Average loss at step 1349999:   4.9\n",
      "Average loss at step 1351999:   4.7\n",
      "Average loss at step 1353999:   4.8\n",
      "Average loss at step 1355999:   4.7\n",
      "Average loss at step 1357999:   4.7\n",
      "Average loss at step 1359999:   4.7\n",
      "Average loss at step 1361999:   4.8\n",
      "Average loss at step 1363999:   4.7\n",
      "Average loss at step 1365999:   4.8\n",
      "Average loss at step 1367999:   4.7\n",
      "Average loss at step 1369999:   4.8\n",
      "Average loss at step 1371999:   4.8\n",
      "Average loss at step 1373999:   4.8\n",
      "Average loss at step 1375999:   4.8\n",
      "Average loss at step 1377999:   4.6\n",
      "Average loss at step 1379999:   4.8\n",
      "Average loss at step 1381999:   4.7\n",
      "Average loss at step 1383999:   4.6\n",
      "Average loss at step 1385999:   4.8\n",
      "Average loss at step 1387999:   4.6\n",
      "Average loss at step 1389999:   4.4\n",
      "Average loss at step 1391999:   4.4\n",
      "Average loss at step 1393999:   4.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 1395999:   6.8\n",
      "Average loss at step 1397999:   4.6\n",
      "Average loss at step 1399999:   4.5\n",
      "Average loss at step 1401999:   4.5\n",
      "Average loss at step 1403999:   4.6\n",
      "Average loss at step 1405999:   4.8\n",
      "Average loss at step 1407999:   4.8\n",
      "Average loss at step 1409999:   4.8\n",
      "Average loss at step 1411999:   4.8\n",
      "Average loss at step 1413999:   4.7\n",
      "Average loss at step 1415999:   4.7\n",
      "Average loss at step 1417999:   4.6\n",
      "Average loss at step 1419999:   4.7\n",
      "Average loss at step 1421999:   4.8\n",
      "Average loss at step 1423999:   4.9\n",
      "Average loss at step 1425999:   4.7\n",
      "Average loss at step 1427999:   4.8\n",
      "Average loss at step 1429999:   4.8\n",
      "Average loss at step 1431999:   4.7\n",
      "Average loss at step 1433999:   4.7\n",
      "Average loss at step 1435999:   4.8\n",
      "Average loss at step 1437999:   4.8\n",
      "Average loss at step 1439999:   4.7\n",
      "Average loss at step 1441999:   4.7\n",
      "Average loss at step 1443999:   4.6\n",
      "Average loss at step 1445999:   4.8\n",
      "Average loss at step 1447999:   4.8\n",
      "Average loss at step 1449999:   4.7\n",
      "Average loss at step 1451999:   4.8\n",
      "Average loss at step 1453999:   4.8\n",
      "Average loss at step 1455999:   4.8\n",
      "Average loss at step 1457999:   4.8\n",
      "Average loss at step 1459999:   4.9\n",
      "Average loss at step 1461999:   4.8\n",
      "Average loss at step 1463999:   4.8\n",
      "Average loss at step 1465999:   4.8\n",
      "Average loss at step 1467999:   4.8\n",
      "Average loss at step 1469999:   4.7\n",
      "Average loss at step 1471999:   4.8\n",
      "Average loss at step 1473999:   4.8\n",
      "Average loss at step 1475999:   4.7\n",
      "Average loss at step 1477999:   4.8\n",
      "Average loss at step 1479999:   4.8\n",
      "Average loss at step 1481999:   4.7\n",
      "Average loss at step 1483999:   4.8\n",
      "Average loss at step 1485999:   4.7\n",
      "Average loss at step 1487999:   4.8\n",
      "Average loss at step 1489999:   4.2\n",
      "Average loss at step 1491999:   4.0\n",
      "Average loss at step 1493999:   4.0\n",
      "Average loss at step 1495999:   4.8\n",
      "Average loss at step 1497999:   4.8\n",
      "Average loss at step 1499999:   4.8\n",
      "Average loss at step 1501999:   4.8\n",
      "Average loss at step 1503999:   4.7\n",
      "Average loss at step 1505999:   4.8\n",
      "Average loss at step 1507999:   4.7\n",
      "Average loss at step 1509999:   4.8\n",
      "Average loss at step 1511999:   4.7\n",
      "Average loss at step 1513999:   4.8\n",
      "Average loss at step 1515999:   4.8\n",
      "Average loss at step 1517999:   4.7\n",
      "Average loss at step 1519999:   4.9\n",
      "Average loss at step 1521999:   4.8\n",
      "Average loss at step 1523999:   4.7\n",
      "Average loss at step 1525999:   4.7\n",
      "Average loss at step 1527999:   4.7\n",
      "Average loss at step 1529999:   4.7\n",
      "Average loss at step 1531999:   4.7\n",
      "Average loss at step 1533999:   4.7\n",
      "Average loss at step 1535999:   4.8\n",
      "Average loss at step 1537999:   4.7\n",
      "Average loss at step 1539999:   4.7\n",
      "Average loss at step 1541999:   4.6\n",
      "Average loss at step 1543999:   4.7\n",
      "Average loss at step 1545999:   4.5\n",
      "Average loss at step 1547999:   4.5\n",
      "Average loss at step 1549999:   4.8\n",
      "Average loss at step 1551999:   4.7\n",
      "Average loss at step 1553999:   4.7\n",
      "Average loss at step 1555999:   4.7\n",
      "Average loss at step 1557999:   4.7\n",
      "Average loss at step 1559999:   4.7\n",
      "Average loss at step 1561999:   4.7\n",
      "Average loss at step 1563999:   4.7\n",
      "Average loss at step 1565999:   4.8\n",
      "Average loss at step 1567999:   4.8\n",
      "Average loss at step 1569999:   4.7\n",
      "Average loss at step 1571999:   4.7\n",
      "Average loss at step 1573999:   4.8\n",
      "Average loss at step 1575999:   4.6\n",
      "Average loss at step 1577999:   4.8\n",
      "Average loss at step 1579999:   4.7\n",
      "Average loss at step 1581999:   4.7\n",
      "Average loss at step 1583999:   4.8\n",
      "Average loss at step 1585999:   4.8\n",
      "Average loss at step 1587999:   4.8\n",
      "Average loss at step 1589999:   4.8\n",
      "Average loss at step 1591999:   4.7\n",
      "Average loss at step 1593999:   4.8\n",
      "Average loss at step 1595999:   4.8\n",
      "Average loss at step 1597999:   4.7\n",
      "Average loss at step 1599999:   4.8\n",
      "Average loss at step 1601999:   4.8\n",
      "Average loss at step 1603999:  11.1\n",
      "Average loss at step 1605999:   5.1\n",
      "Average loss at step 1607999:   4.7\n",
      "Average loss at step 1609999:   4.8\n",
      "Average loss at step 1611999:   4.9\n",
      "Average loss at step 1613999:   4.8\n",
      "Average loss at step 1615999:   4.7\n",
      "Average loss at step 1617999:   4.9\n",
      "Average loss at step 1619999:   4.8\n",
      "Average loss at step 1621999:   4.8\n",
      "Average loss at step 1623999:   4.6\n",
      "Average loss at step 1625999:   4.4\n",
      "Average loss at step 1627999:   4.7\n",
      "Average loss at step 1629999:   4.7\n",
      "Average loss at step 1631999:   4.7\n",
      "Average loss at step 1633999:   4.7\n",
      "Average loss at step 1635999:   4.8\n",
      "Average loss at step 1637999:   4.9\n",
      "Average loss at step 1639999:   4.6\n",
      "Average loss at step 1641999:   4.6\n",
      "Average loss at step 1643999:   4.9\n",
      "Average loss at step 1645999:   4.6\n",
      "Average loss at step 1647999:   4.7\n",
      "Average loss at step 1649999:   4.7\n",
      "Average loss at step 1651999:   4.6\n",
      "Average loss at step 1653999:   4.6\n",
      "Average loss at step 1655999:   4.8\n",
      "Average loss at step 1657999:   4.8\n",
      "Average loss at step 1659999:   4.7\n",
      "Average loss at step 1661999:   4.6\n",
      "Average loss at step 1663999:   4.7\n",
      "Average loss at step 1665999:   4.7\n",
      "Average loss at step 1667999:   4.8\n",
      "Average loss at step 1669999:   4.7\n",
      "Average loss at step 1671999:   4.7\n",
      "Average loss at step 1673999:   4.7\n",
      "Average loss at step 1675999:   4.7\n",
      "Average loss at step 1677999:   4.7\n",
      "Average loss at step 1679999:   4.8\n",
      "Average loss at step 1681999:   4.7\n",
      "Average loss at step 1683999:   4.9\n",
      "Average loss at step 1685999:   4.8\n",
      "Average loss at step 1687999:   4.8\n",
      "Average loss at step 1689999:   4.7\n",
      "Average loss at step 1691999:   4.8\n",
      "Average loss at step 1693999:   4.9\n",
      "Average loss at step 1695999:   4.6\n",
      "Average loss at step 1697999:   4.7\n",
      "Average loss at step 1699999:   4.7\n",
      "Average loss at step 1701999:   4.7\n",
      "Average loss at step 1703999:   4.8\n",
      "Average loss at step 1705999:   4.6\n",
      "Average loss at step 1707999:   4.8\n",
      "Average loss at step 1709999:   4.8\n",
      "Average loss at step 1711999:   4.7\n",
      "Average loss at step 1713999:   4.7\n",
      "Average loss at step 1715999:   4.7\n",
      "Average loss at step 1717999:   4.8\n",
      "Average loss at step 1719999:   4.8\n",
      "Average loss at step 1721999:   4.7\n",
      "Average loss at step 1723999:   4.8\n",
      "Average loss at step 1725999:   4.8\n",
      "Average loss at step 1727999:   4.8\n",
      "Average loss at step 1729999:   4.7\n",
      "Average loss at step 1731999:   4.7\n",
      "Average loss at step 1733999:   4.7\n",
      "Average loss at step 1735999:   4.6\n",
      "Average loss at step 1737999:   4.9\n",
      "Average loss at step 1739999:   4.7\n",
      "Average loss at step 1741999:   4.7\n",
      "Average loss at step 1743999:   4.7\n",
      "Average loss at step 1745999:   4.7\n",
      "Average loss at step 1747999:   4.7\n",
      "Average loss at step 1749999:   4.8\n",
      "Average loss at step 1751999:   4.7\n",
      "Average loss at step 1753999:   4.8\n",
      "Average loss at step 1755999:   4.6\n",
      "Average loss at step 1757999:   4.7\n",
      "Average loss at step 1759999:   4.8\n",
      "Average loss at step 1761999:   5.6\n",
      "Average loss at step 1763999:   5.3\n",
      "Average loss at step 1765999:   5.4\n",
      "Average loss at step 1767999:   5.5\n",
      "Average loss at step 1769999:   4.9\n",
      "Average loss at step 1771999:   4.8\n",
      "Average loss at step 1773999:   4.9\n",
      "Average loss at step 1775999:   4.8\n",
      "Average loss at step 1777999:   4.8\n",
      "Average loss at step 1779999:   4.7\n",
      "Average loss at step 1781999:   4.8\n",
      "Average loss at step 1783999:   4.7\n",
      "Average loss at step 1785999:   4.8\n",
      "Average loss at step 1787999:   5.1\n",
      "Average loss at step 1789999:   4.8\n",
      "Average loss at step 1791999:   4.8\n",
      "Average loss at step 1793999:   4.7\n",
      "Average loss at step 1795999:   4.8\n",
      "Average loss at step 1797999:   4.8\n",
      "Average loss at step 1799999:   4.8\n",
      "Average loss at step 1801999:   4.8\n",
      "Average loss at step 1803999:   4.7\n",
      "Average loss at step 1805999:   4.7\n",
      "Average loss at step 1807999:   4.6\n",
      "Average loss at step 1809999:   4.7\n",
      "Average loss at step 1811999:   4.8\n",
      "Average loss at step 1813999:   4.7\n",
      "Average loss at step 1815999:   4.6\n",
      "Average loss at step 1817999:   4.8\n",
      "Average loss at step 1819999:   4.8\n",
      "Average loss at step 1821999:   4.8\n",
      "Average loss at step 1823999:   4.7\n",
      "Average loss at step 1825999:   4.6\n",
      "Average loss at step 1827999:   4.7\n",
      "Average loss at step 1829999:   4.8\n",
      "Average loss at step 1831999:   4.7\n",
      "Average loss at step 1833999:   4.8\n",
      "Average loss at step 1835999:   4.7\n",
      "Average loss at step 1837999:   4.7\n",
      "Average loss at step 1839999:   4.8\n",
      "Average loss at step 1841999:   4.7\n",
      "Average loss at step 1843999:   4.8\n",
      "Average loss at step 1845999:   4.7\n",
      "Average loss at step 1847999:   4.7\n",
      "Average loss at step 1849999:   4.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 1851999:   4.8\n",
      "Average loss at step 1853999:   4.7\n",
      "Average loss at step 1855999:   4.8\n",
      "Average loss at step 1857999:   4.7\n",
      "Average loss at step 1859999:   4.7\n",
      "Average loss at step 1861999:   4.7\n",
      "Average loss at step 1863999:   4.7\n",
      "Average loss at step 1865999:   4.8\n",
      "Average loss at step 1867999:   4.8\n",
      "Average loss at step 1869999:   4.8\n",
      "Average loss at step 1871999:   4.7\n",
      "Average loss at step 1873999:   4.7\n",
      "Average loss at step 1875999:   4.8\n",
      "Average loss at step 1877999:   4.6\n",
      "Average loss at step 1879999:   4.5\n",
      "Average loss at step 1881999:   4.7\n",
      "Average loss at step 1883999:   4.7\n",
      "Average loss at step 1885999:   4.7\n",
      "Average loss at step 1887999:   4.7\n",
      "Average loss at step 1889999:   4.8\n",
      "Average loss at step 1891999:   4.7\n",
      "Average loss at step 1893999:   4.5\n",
      "Average loss at step 1895999:   4.8\n",
      "Average loss at step 1897999:   4.8\n",
      "Average loss at step 1899999:   4.8\n",
      "Average loss at step 1901999:   4.7\n",
      "Average loss at step 1903999:   4.7\n",
      "Average loss at step 1905999:   4.7\n",
      "Average loss at step 1907999:   4.7\n",
      "Average loss at step 1909999:   4.6\n",
      "Average loss at step 1911999:   4.7\n",
      "Average loss at step 1913999:   4.8\n",
      "Average loss at step 1915999:   4.6\n",
      "Average loss at step 1917999:   4.6\n",
      "Average loss at step 1919999:   4.6\n",
      "Average loss at step 1921999:   4.7\n",
      "Average loss at step 1923999:   4.5\n",
      "Average loss at step 1925999:   4.4\n",
      "Average loss at step 1927999:   4.3\n",
      "Average loss at step 1929999:   4.4\n",
      "Average loss at step 1931999:   4.5\n",
      "Average loss at step 1933999:   4.7\n",
      "Average loss at step 1935999:   4.3\n",
      "Average loss at step 1937999:   4.3\n",
      "Average loss at step 1939999:   4.6\n",
      "Average loss at step 1941999:   4.7\n",
      "Average loss at step 1943999:   4.7\n",
      "Average loss at step 1945999:   4.8\n",
      "Average loss at step 1947999:   4.8\n",
      "Average loss at step 1949999:   4.7\n",
      "Average loss at step 1951999:   4.7\n",
      "Average loss at step 1953999:   4.8\n",
      "Average loss at step 1955999:   4.7\n",
      "Average loss at step 1957999:   4.8\n",
      "Average loss at step 1959999:   4.7\n",
      "Average loss at step 1961999:   4.7\n",
      "Average loss at step 1963999:   4.7\n",
      "Average loss at step 1965999:   4.7\n",
      "Average loss at step 1967999:   4.7\n",
      "Average loss at step 1969999:   4.7\n",
      "Average loss at step 1971999:   4.7\n",
      "Average loss at step 1973999:   4.7\n",
      "Average loss at step 1975999:   4.7\n",
      "Average loss at step 1977999:   4.7\n",
      "Average loss at step 1979999:   4.7\n",
      "Average loss at step 1981999:   4.8\n",
      "Average loss at step 1983999:   4.8\n",
      "Average loss at step 1985999:   4.7\n",
      "Average loss at step 1987999:   4.7\n",
      "Average loss at step 1989999:   4.7\n",
      "Average loss at step 1991999:   4.7\n",
      "Average loss at step 1993999:   4.8\n",
      "Average loss at step 1995999:   4.7\n",
      "Average loss at step 1997999:   4.7\n",
      "Average loss at step 1999999:   4.8\n",
      "Average loss at step 2001999:   4.8\n",
      "Average loss at step 2003999:   4.7\n",
      "Average loss at step 2005999:   4.7\n",
      "Average loss at step 2007999:   4.8\n",
      "Average loss at step 2009999:   4.7\n",
      "Average loss at step 2011999:   4.7\n",
      "Average loss at step 2013999:   4.7\n",
      "Average loss at step 2015999:   4.7\n",
      "Average loss at step 2017999:   4.7\n",
      "Average loss at step 2019999:   4.7\n",
      "Average loss at step 2021999:   4.6\n",
      "Average loss at step 2023999:   4.8\n",
      "Average loss at step 2025999:   4.8\n",
      "Average loss at step 2027999:   4.7\n",
      "Average loss at step 2029999:   4.8\n",
      "Average loss at step 2031999:   4.7\n",
      "Average loss at step 2033999:   4.8\n",
      "Average loss at step 2035999:   4.7\n",
      "Average loss at step 2037999:   4.7\n",
      "Average loss at step 2039999:   4.7\n",
      "Average loss at step 2041999:   4.8\n",
      "Average loss at step 2043999:   4.7\n",
      "Average loss at step 2045999:   4.7\n",
      "Average loss at step 2047999:   4.8\n",
      "Average loss at step 2049999:   4.6\n",
      "Average loss at step 2051999:   4.5\n",
      "Average loss at step 2053999:   4.7\n",
      "Average loss at step 2055999:   4.7\n",
      "Average loss at step 2057999:   4.7\n",
      "Average loss at step 2059999:   4.7\n",
      "Average loss at step 2061999:   4.7\n",
      "Average loss at step 2063999:   4.7\n",
      "Average loss at step 2065999:   4.7\n",
      "Average loss at step 2067999:   4.4\n",
      "Average loss at step 2069999:   4.7\n",
      "Average loss at step 2071999:   4.8\n",
      "Average loss at step 2073999:   4.7\n",
      "Average loss at step 2075999:   4.8\n",
      "Average loss at step 2077999:   4.8\n",
      "Average loss at step 2079999:   4.7\n",
      "Average loss at step 2081999:   4.8\n",
      "Average loss at step 2083999:   4.7\n",
      "Average loss at step 2085999:   4.7\n",
      "Average loss at step 2087999:   4.8\n",
      "Average loss at step 2089999:   4.7\n",
      "Average loss at step 2091999:   4.7\n",
      "Average loss at step 2093999:   4.8\n",
      "Average loss at step 2095999:   4.7\n",
      "Average loss at step 2097999:   4.6\n",
      "Average loss at step 2099999:   4.9\n",
      "Average loss at step 2101999:   4.7\n",
      "Average loss at step 2103999:   4.7\n",
      "Average loss at step 2105999:   4.7\n",
      "Average loss at step 2107999:   4.7\n",
      "Average loss at step 2109999:   4.8\n",
      "Average loss at step 2111999:   4.7\n",
      "Average loss at step 2113999:   4.7\n",
      "Average loss at step 2115999:   4.7\n",
      "Average loss at step 2117999:   4.7\n",
      "Average loss at step 2119999:   4.7\n",
      "Average loss at step 2121999:   4.7\n",
      "Average loss at step 2123999:   4.6\n",
      "Average loss at step 2125999:   4.7\n",
      "Average loss at step 2127999:   4.7\n",
      "Average loss at step 2129999:   4.7\n",
      "Average loss at step 2131999:   4.6\n",
      "Average loss at step 2133999:   4.8\n",
      "Average loss at step 2135999:   4.8\n",
      "Average loss at step 2137999:   4.7\n",
      "Average loss at step 2139999:   4.7\n",
      "Average loss at step 2141999:   4.7\n",
      "Average loss at step 2143999:   4.7\n",
      "Average loss at step 2145999:   4.6\n",
      "Average loss at step 2147999:   4.7\n",
      "Average loss at step 2149999:   4.7\n",
      "Average loss at step 2151999:   4.7\n",
      "Average loss at step 2153999:   4.8\n",
      "Average loss at step 2155999:   4.7\n",
      "Average loss at step 2157999:   4.6\n",
      "Average loss at step 2159999:   4.9\n",
      "Average loss at step 2161999:   4.7\n",
      "Average loss at step 2163999:   4.8\n",
      "Average loss at step 2165999:   4.8\n",
      "Average loss at step 2167999:   4.7\n",
      "Average loss at step 2169999:   4.7\n",
      "Average loss at step 2171999:   4.7\n",
      "Average loss at step 2173999:   4.7\n",
      "Average loss at step 2175999:   4.8\n",
      "Average loss at step 2177999:   4.7\n",
      "Average loss at step 2179999:   4.6\n",
      "Average loss at step 2181999:   4.7\n",
      "Average loss at step 2183999:   4.7\n",
      "Average loss at step 2185999:   6.2\n",
      "Average loss at step 2187999:   5.0\n",
      "Average loss at step 2189999:   4.8\n",
      "Average loss at step 2191999:   4.9\n",
      "Average loss at step 2193999:   4.8\n",
      "Average loss at step 2195999:   4.7\n",
      "Average loss at step 2197999:   4.8\n",
      "Average loss at step 2199999:   4.8\n",
      "Average loss at step 2201999:   4.8\n",
      "Average loss at step 2203999:   4.7\n",
      "Average loss at step 2205999:   4.6\n",
      "Average loss at step 2207999:   4.7\n",
      "Average loss at step 2209999:   4.7\n",
      "Average loss at step 2211999:   4.7\n",
      "Average loss at step 2213999:   4.6\n",
      "Average loss at step 2215999:   4.6\n",
      "Average loss at step 2217999:   4.8\n",
      "Average loss at step 2219999:   4.7\n",
      "Average loss at step 2221999:   5.0\n",
      "Average loss at step 2223999:   4.7\n",
      "Average loss at step 2225999:   4.7\n",
      "Average loss at step 2227999:   4.7\n",
      "Average loss at step 2229999:   4.8\n",
      "Average loss at step 2231999:   4.7\n",
      "Average loss at step 2233999:   4.8\n",
      "Average loss at step 2235999:   4.7\n",
      "Average loss at step 2237999:   4.7\n",
      "Average loss at step 2239999:   4.7\n",
      "Average loss at step 2241999:   4.6\n",
      "Average loss at step 2243999:   4.8\n",
      "Average loss at step 2245999:   4.7\n",
      "Average loss at step 2247999:   4.8\n",
      "Average loss at step 2249999:   4.7\n",
      "Average loss at step 2251999:   4.6\n",
      "Average loss at step 2253999:   4.6\n",
      "Average loss at step 2255999:   4.7\n",
      "Average loss at step 2257999:   4.6\n",
      "Average loss at step 2259999:   4.6\n",
      "Average loss at step 2261999:   4.7\n",
      "Average loss at step 2263999:   4.7\n",
      "Average loss at step 2265999:   4.7\n",
      "Average loss at step 2267999:   4.7\n",
      "Average loss at step 2269999:   4.7\n",
      "Average loss at step 2271999:   4.8\n",
      "Average loss at step 2273999:   4.8\n",
      "Average loss at step 2275999:   4.8\n",
      "Average loss at step 2277999:   4.7\n",
      "Average loss at step 2279999:   4.3\n",
      "Average loss at step 2281999:   4.7\n",
      "Average loss at step 2283999:   4.7\n",
      "Average loss at step 2285999:   4.7\n",
      "Average loss at step 2287999:   4.7\n",
      "Average loss at step 2289999:   4.7\n",
      "Average loss at step 2291999:   4.7\n",
      "Average loss at step 2293999:   4.8\n",
      "Average loss at step 2295999:   4.8\n",
      "Average loss at step 2297999:   4.6\n",
      "Average loss at step 2299999:   4.7\n",
      "Average loss at step 2301999:   4.7\n",
      "Average loss at step 2303999:   4.7\n",
      "Average loss at step 2305999:   4.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 2307999:   4.7\n",
      "Average loss at step 2309999:   4.7\n",
      "Average loss at step 2311999:   4.7\n",
      "Average loss at step 2313999:   4.8\n",
      "Average loss at step 2315999:   4.7\n",
      "Average loss at step 2317999:   4.7\n",
      "Average loss at step 2319999:   4.8\n",
      "Average loss at step 2321999:   4.7\n",
      "Average loss at step 2323999:   4.6\n",
      "Average loss at step 2325999:   4.6\n",
      "Average loss at step 2327999:   4.7\n",
      "Average loss at step 2329999:   4.7\n",
      "Average loss at step 2331999:   4.7\n",
      "Average loss at step 2333999:   4.7\n",
      "Average loss at step 2335999:   4.6\n",
      "Average loss at step 2337999:   4.8\n",
      "Average loss at step 2339999:   4.7\n",
      "Average loss at step 2341999:   4.7\n",
      "Average loss at step 2343999:   4.8\n",
      "Average loss at step 2345999:   4.7\n",
      "Average loss at step 2347999:   4.8\n",
      "Average loss at step 2349999:   4.8\n",
      "Average loss at step 2351999:   4.7\n",
      "Average loss at step 2353999:   4.8\n",
      "Average loss at step 2355999:   4.7\n",
      "Average loss at step 2357999:   4.7\n",
      "Average loss at step 2359999:   4.7\n",
      "Average loss at step 2361999:   4.7\n",
      "Average loss at step 2363999:   4.7\n",
      "Average loss at step 2365999:   4.6\n",
      "Average loss at step 2367999:   4.5\n",
      "Average loss at step 2369999:   4.7\n",
      "Average loss at step 2371999:   4.6\n",
      "Average loss at step 2373999:   4.7\n",
      "Average loss at step 2375999:   4.6\n",
      "Average loss at step 2377999:   4.7\n",
      "Average loss at step 2379999:   4.8\n",
      "Average loss at step 2381999:   4.7\n",
      "Average loss at step 2383999:   4.7\n",
      "Average loss at step 2385999:   4.7\n",
      "Average loss at step 2387999:   4.7\n",
      "Average loss at step 2389999:   4.7\n",
      "Average loss at step 2391999:   4.7\n",
      "Average loss at step 2393999:   4.6\n",
      "Average loss at step 2395999:   4.6\n",
      "Average loss at step 2397999:   4.8\n",
      "Average loss at step 2399999:   4.7\n",
      "Average loss at step 2401999:   4.8\n",
      "Average loss at step 2403999:   4.6\n",
      "Average loss at step 2405999:   4.7\n",
      "Average loss at step 2407999:   4.6\n",
      "Average loss at step 2409999:   4.7\n",
      "Average loss at step 2411999:   4.6\n",
      "Average loss at step 2413999:   4.7\n",
      "Average loss at step 2415999:   4.7\n",
      "Average loss at step 2417999:   4.7\n",
      "Average loss at step 2419999:   4.7\n",
      "Average loss at step 2421999:   4.7\n",
      "Average loss at step 2423999:   4.7\n",
      "Average loss at step 2425999:   4.7\n",
      "Average loss at step 2427999:   4.7\n",
      "Average loss at step 2429999:   4.7\n",
      "Average loss at step 2431999:   4.7\n",
      "Average loss at step 2433999:   4.7\n",
      "Average loss at step 2435999:   4.7\n",
      "Average loss at step 2437999:   4.7\n",
      "Average loss at step 2439999:   4.7\n",
      "Average loss at step 2441999:   4.6\n",
      "Average loss at step 2443999:   4.7\n",
      "Average loss at step 2445999:   4.6\n",
      "Average loss at step 2447999:   4.7\n",
      "Average loss at step 2449999:   4.6\n",
      "Average loss at step 2451999:   4.7\n",
      "Average loss at step 2453999:   4.6\n",
      "Average loss at step 2455999:   4.5\n",
      "Average loss at step 2457999:   4.6\n",
      "Average loss at step 2459999:   4.6\n",
      "Average loss at step 2461999:   4.5\n",
      "Average loss at step 2463999:   4.7\n",
      "Average loss at step 2465999:   4.8\n",
      "Average loss at step 2467999:   4.7\n",
      "Average loss at step 2469999:   4.7\n",
      "Average loss at step 2471999:   4.7\n",
      "Average loss at step 2473999:   4.7\n",
      "Average loss at step 2475999:   4.7\n",
      "Average loss at step 2477999:   4.7\n",
      "Average loss at step 2479999:   4.7\n",
      "Average loss at step 2481999:   4.7\n",
      "Average loss at step 2483999:   4.9\n",
      "Average loss at step 2485999:   4.6\n",
      "Average loss at step 2487999:   4.7\n",
      "Average loss at step 2489999:   4.7\n",
      "Average loss at step 2491999:   4.7\n",
      "Average loss at step 2493999:   4.7\n",
      "Average loss at step 2495999:   4.7\n",
      "Average loss at step 2497999:   4.6\n",
      "Average loss at step 2499999:   4.7\n",
      "Average loss at step 2501999:   4.7\n",
      "Average loss at step 2503999:   4.6\n",
      "Average loss at step 2505999:   4.7\n",
      "Average loss at step 2507999:   4.7\n",
      "Average loss at step 2509999:   4.7\n",
      "Average loss at step 2511999:   4.7\n",
      "Average loss at step 2513999:   4.7\n",
      "Average loss at step 2515999:   4.7\n",
      "Average loss at step 2517999:   4.7\n",
      "Average loss at step 2519999:   4.8\n",
      "Average loss at step 2521999:   4.7\n",
      "Average loss at step 2523999:   4.7\n",
      "Average loss at step 2525999:   4.7\n",
      "Average loss at step 2527999:   4.7\n",
      "Average loss at step 2529999:   4.7\n",
      "Average loss at step 2531999:   4.7\n",
      "Average loss at step 2533999:   4.5\n",
      "Average loss at step 2535999:   4.8\n",
      "Average loss at step 2537999:   4.7\n",
      "Average loss at step 2539999:   4.7\n",
      "Average loss at step 2541999:   4.7\n",
      "Average loss at step 2543999:   4.7\n",
      "Average loss at step 2545999:   4.7\n",
      "Average loss at step 2547999:   4.7\n",
      "Average loss at step 2549999:   4.7\n",
      "Average loss at step 2551999:   4.7\n",
      "Average loss at step 2553999:   4.6\n",
      "Average loss at step 2555999:   4.5\n",
      "Average loss at step 2557999:   4.6\n",
      "Average loss at step 2559999:   4.7\n",
      "Average loss at step 2561999:   4.7\n",
      "Average loss at step 2563999:   4.7\n",
      "Average loss at step 2565999:   4.7\n",
      "Average loss at step 2567999:   4.7\n",
      "Average loss at step 2569999:   4.8\n",
      "Average loss at step 2571999:   4.5\n",
      "Average loss at step 2573999:   4.7\n",
      "Average loss at step 2575999:   4.7\n",
      "Average loss at step 2577999:   4.7\n",
      "Average loss at step 2579999:   4.7\n",
      "Average loss at step 2581999:   4.7\n",
      "Average loss at step 2583999:   4.7\n",
      "Average loss at step 2585999:   4.7\n",
      "Average loss at step 2587999:   4.7\n",
      "Average loss at step 2589999:   4.7\n",
      "Average loss at step 2591999:   4.7\n",
      "Average loss at step 2593999:   4.7\n",
      "Average loss at step 2595999:   4.7\n",
      "Average loss at step 2597999:   4.7\n",
      "Average loss at step 2599999:   4.6\n",
      "Average loss at step 2601999:   4.6\n",
      "Average loss at step 2603999:   4.4\n",
      "Average loss at step 2605999:   4.6\n",
      "Average loss at step 2607999:   4.7\n",
      "Average loss at step 2609999:   4.8\n",
      "Average loss at step 2611999:   4.7\n",
      "Average loss at step 2613999:   4.7\n",
      "Average loss at step 2615999:   4.7\n",
      "Average loss at step 2617999:   4.7\n",
      "Average loss at step 2619999:   4.7\n",
      "Average loss at step 2621999:   4.7\n",
      "Average loss at step 2623999:   4.4\n",
      "Average loss at step 2625999:   4.7\n",
      "Average loss at step 2627999:   4.7\n",
      "Average loss at step 2629999:   4.6\n",
      "Average loss at step 2631999:   4.7\n",
      "Average loss at step 2633999:   4.7\n",
      "Average loss at step 2635999:   4.8\n",
      "Average loss at step 2637999:   4.7\n",
      "Average loss at step 2639999:   4.6\n",
      "Average loss at step 2641999:   4.7\n",
      "Average loss at step 2643999:   4.8\n",
      "Average loss at step 2645999:   4.6\n",
      "Average loss at step 2647999:   4.6\n",
      "Average loss at step 2649999:   4.7\n",
      "Average loss at step 2651999:   4.7\n",
      "Average loss at step 2653999:   4.7\n",
      "Average loss at step 2655999:   4.6\n",
      "Average loss at step 2657999:   4.7\n",
      "Average loss at step 2659999:   4.7\n",
      "Average loss at step 2661999:   4.6\n",
      "Average loss at step 2663999:   4.7\n",
      "Average loss at step 2665999:   4.8\n",
      "Average loss at step 2667999:   4.6\n",
      "Average loss at step 2669999:   4.8\n",
      "Average loss at step 2671999:   4.7\n",
      "Average loss at step 2673999:   4.7\n",
      "Average loss at step 2675999:   4.7\n",
      "Average loss at step 2677999:   4.7\n",
      "Average loss at step 2679999:   5.0\n",
      "Average loss at step 2681999:   4.7\n",
      "Average loss at step 2683999:   4.7\n",
      "Average loss at step 2685999:   4.7\n",
      "Average loss at step 2687999:   4.7\n",
      "Average loss at step 2689999:   4.8\n",
      "Average loss at step 2691999:   4.5\n",
      "Average loss at step 2693999:   4.8\n",
      "Average loss at step 2695999:   4.7\n",
      "Average loss at step 2697999:   4.7\n",
      "Average loss at step 2699999:   4.7\n",
      "Average loss at step 2701999:   4.7\n",
      "Average loss at step 2703999:   4.7\n",
      "Average loss at step 2705999:   4.7\n",
      "Average loss at step 2707999:   4.8\n",
      "Average loss at step 2709999:   4.6\n",
      "Average loss at step 2711999:   4.7\n",
      "Average loss at step 2713999:   4.7\n",
      "Average loss at step 2715999:   4.8\n",
      "Average loss at step 2717999:   4.7\n",
      "Average loss at step 2719999:   4.7\n",
      "Average loss at step 2721999:   4.7\n",
      "Average loss at step 2723999:   4.7\n",
      "Average loss at step 2725999:   4.7\n",
      "Average loss at step 2727999:   4.7\n",
      "Average loss at step 2729999:   4.7\n",
      "Average loss at step 2731999:   4.7\n",
      "Average loss at step 2733999:   4.7\n",
      "Average loss at step 2735999:   4.7\n",
      "Average loss at step 2737999:   4.7\n",
      "Average loss at step 2739999:   4.7\n",
      "Average loss at step 2741999:   4.7\n",
      "Average loss at step 2743999:   4.7\n",
      "Average loss at step 2745999:   4.7\n",
      "Average loss at step 2747999:   4.6\n",
      "Average loss at step 2749999:   4.8\n",
      "Average loss at step 2751999:   4.7\n",
      "Average loss at step 2753999:   4.6\n",
      "Average loss at step 2755999:   4.6\n",
      "Average loss at step 2757999:   4.7\n",
      "Average loss at step 2759999:   4.7\n",
      "Average loss at step 2761999:   4.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 2763999:   4.6\n",
      "Average loss at step 2765999:   4.7\n",
      "Average loss at step 2767999:   4.7\n",
      "Average loss at step 2769999:   4.7\n",
      "Average loss at step 2771999:   4.7\n",
      "Average loss at step 2773999:   4.7\n",
      "Average loss at step 2775999:   4.6\n",
      "Average loss at step 2777999:   4.6\n",
      "Average loss at step 2779999:   4.7\n",
      "Average loss at step 2781999:   4.7\n",
      "Average loss at step 2783999:   4.6\n",
      "Average loss at step 2785999:   4.5\n",
      "Average loss at step 2787999:   4.5\n",
      "Average loss at step 2789999:   4.7\n",
      "Average loss at step 2791999:   4.7\n",
      "Average loss at step 2793999:   4.7\n",
      "Average loss at step 2795999:   4.6\n",
      "Average loss at step 2797999:   4.6\n",
      "Average loss at step 2799999:   4.6\n",
      "Average loss at step 2801999:   4.7\n",
      "Average loss at step 2803999:   4.6\n",
      "Average loss at step 2805999:   4.7\n",
      "Average loss at step 2807999:   4.7\n",
      "Average loss at step 2809999:   4.7\n",
      "Average loss at step 2811999:   4.8\n",
      "Average loss at step 2813999:   4.6\n",
      "Average loss at step 2815999:   4.7\n",
      "Average loss at step 2817999:   4.7\n",
      "Average loss at step 2819999:   4.7\n",
      "Average loss at step 2821999:   4.7\n",
      "Average loss at step 2823999:   4.7\n",
      "Average loss at step 2825999:   4.7\n",
      "Average loss at step 2827999:   4.7\n",
      "Average loss at step 2829999:   4.7\n",
      "Average loss at step 2831999:   4.7\n",
      "Average loss at step 2833999:   4.7\n",
      "Average loss at step 2835999:   4.5\n",
      "Average loss at step 2837999:   4.6\n",
      "Average loss at step 2839999:   4.7\n",
      "Average loss at step 2841999:   4.7\n",
      "Average loss at step 2843999:   4.6\n",
      "Average loss at step 2845999:   4.6\n",
      "Average loss at step 2847999:   4.8\n",
      "Average loss at step 2849999:   4.7\n",
      "Average loss at step 2851999:   4.6\n",
      "Average loss at step 2853999:   4.7\n",
      "Average loss at step 2855999:   4.8\n",
      "Average loss at step 2857999:   4.5\n",
      "Average loss at step 2859999:   4.6\n",
      "Average loss at step 2861999:   4.7\n",
      "Average loss at step 2863999:   4.7\n",
      "Average loss at step 2865999:   4.7\n",
      "Average loss at step 2867999:   4.5\n",
      "Average loss at step 2869999:   4.3\n",
      "Average loss at step 2871999:   4.3\n",
      "Average loss at step 2873999:   4.7\n",
      "Average loss at step 2875999:   4.6\n",
      "Average loss at step 2877999:   4.4\n",
      "Average loss at step 2879999:   4.7\n",
      "Average loss at step 2881999:   4.6\n",
      "Average loss at step 2883999:   4.8\n",
      "Average loss at step 2885999:   4.7\n",
      "Average loss at step 2887999:   4.7\n",
      "Average loss at step 2889999:   4.7\n",
      "Average loss at step 2891999:   4.7\n",
      "Average loss at step 2893999:   4.7\n",
      "Average loss at step 2895999:   4.8\n",
      "Average loss at step 2897999:   4.8\n",
      "Average loss at step 2899999:   4.7\n",
      "Average loss at step 2901999:   4.7\n",
      "Average loss at step 2903999:   4.6\n",
      "Average loss at step 2905999:   4.7\n",
      "Average loss at step 2907999:   4.6\n",
      "Average loss at step 2909999:   4.6\n",
      "Average loss at step 2911999:   4.7\n",
      "Average loss at step 2913999:   4.6\n",
      "Average loss at step 2915999:   4.7\n",
      "Average loss at step 2917999:   4.7\n",
      "Average loss at step 2919999:   4.7\n",
      "Average loss at step 2921999:   4.7\n",
      "Average loss at step 2923999:   4.7\n",
      "Average loss at step 2925999:   4.6\n",
      "Average loss at step 2927999:   4.6\n",
      "Average loss at step 2929999:   4.6\n",
      "Average loss at step 2931999:   4.7\n",
      "Average loss at step 2933999:   4.8\n",
      "Average loss at step 2935999:   4.7\n",
      "Average loss at step 2937999:   4.7\n",
      "Average loss at step 2939999:   4.6\n",
      "Average loss at step 2941999:   4.7\n",
      "Average loss at step 2943999:   4.7\n",
      "Average loss at step 2945999:   4.7\n",
      "Average loss at step 2947999:   4.7\n",
      "Average loss at step 2949999:   4.7\n",
      "Average loss at step 2951999:   4.7\n",
      "Average loss at step 2953999:   4.6\n",
      "Average loss at step 2955999:   4.4\n",
      "Average loss at step 2957999:   4.7\n",
      "Average loss at step 2959999:   4.7\n",
      "Average loss at step 2961999:   4.6\n",
      "Average loss at step 2963999:   4.7\n",
      "Average loss at step 2965999:   4.7\n",
      "Average loss at step 2967999:   4.7\n",
      "Average loss at step 2969999:   4.7\n",
      "Average loss at step 2971999:   4.7\n",
      "Average loss at step 2973999:   4.6\n",
      "Average loss at step 2975999:   4.6\n",
      "Average loss at step 2977999:   4.8\n",
      "Average loss at step 2979999:   4.7\n",
      "Average loss at step 2981999:   4.7\n",
      "Average loss at step 2983999:   4.7\n",
      "Average loss at step 2985999:   4.6\n",
      "Average loss at step 2987999:   4.7\n",
      "Average loss at step 2989999:   4.6\n",
      "Average loss at step 2991999:   4.6\n",
      "Average loss at step 2993999:   4.4\n",
      "Average loss at step 2995999:   4.6\n",
      "Average loss at step 2997999:   4.7\n",
      "Average loss at step 2999999:   4.7\n",
      "Average loss at step 3001999:   4.6\n",
      "Average loss at step 3003999:   4.7\n",
      "Average loss at step 3005999:   4.7\n",
      "Average loss at step 3007999:   4.7\n",
      "Average loss at step 3009999:   4.7\n",
      "Average loss at step 3011999:   4.6\n",
      "Average loss at step 3013999:   4.7\n",
      "Average loss at step 3015999:   4.7\n",
      "Average loss at step 3017999:   4.7\n",
      "Average loss at step 3019999:   4.6\n",
      "Average loss at step 3021999:   4.6\n",
      "Average loss at step 3023999:   4.6\n",
      "Average loss at step 3025999:   4.7\n",
      "Average loss at step 3027999:   4.6\n",
      "Average loss at step 3029999:   4.7\n",
      "Average loss at step 3031999:   4.7\n",
      "Average loss at step 3033999:   4.5\n",
      "Average loss at step 3035999:   4.5\n",
      "Average loss at step 3037999:   4.7\n",
      "Average loss at step 3039999:   4.6\n",
      "Average loss at step 3041999:   4.7\n",
      "Average loss at step 3043999:   4.8\n",
      "Average loss at step 3045999:   4.5\n",
      "Average loss at step 3047999:   4.5\n",
      "Average loss at step 3049999:   4.6\n",
      "Average loss at step 3051999:   4.7\n",
      "Average loss at step 3053999:   4.7\n",
      "Average loss at step 3055999:   4.7\n",
      "Average loss at step 3057999:   4.7\n",
      "Average loss at step 3059999:   4.7\n",
      "Average loss at step 3061999:   4.7\n",
      "Average loss at step 3063999:   4.6\n",
      "Average loss at step 3065999:   4.7\n",
      "Average loss at step 3067999:   4.7\n",
      "Average loss at step 3069999:   4.6\n",
      "Average loss at step 3071999:   4.7\n",
      "Average loss at step 3073999:   4.7\n",
      "Average loss at step 3075999:   4.7\n",
      "Average loss at step 3077999:   4.6\n",
      "Average loss at step 3079999:   4.7\n",
      "Average loss at step 3081999:   4.8\n",
      "Average loss at step 3083999:   4.7\n",
      "Average loss at step 3085999:   4.6\n",
      "Average loss at step 3087999:   4.7\n",
      "Average loss at step 3089999:   4.7\n",
      "Average loss at step 3091999:   4.7\n",
      "Average loss at step 3093999:   4.7\n",
      "Average loss at step 3095999:   4.7\n",
      "Average loss at step 3097999:   4.6\n",
      "Average loss at step 3099999:   4.6\n",
      "Average loss at step 3101999:   4.7\n",
      "Average loss at step 3103999:   4.7\n",
      "Average loss at step 3105999:   4.7\n",
      "Average loss at step 3107999:   4.6\n",
      "Average loss at step 3109999:   4.7\n",
      "Average loss at step 3111999:   4.6\n",
      "Average loss at step 3113999:   4.6\n",
      "Average loss at step 3115999:   4.7\n",
      "Average loss at step 3117999:   4.6\n",
      "Average loss at step 3119999:   4.7\n",
      "Average loss at step 3121999:   4.7\n",
      "Average loss at step 3123999:   4.6\n",
      "Average loss at step 3125999:   4.7\n",
      "Average loss at step 3127999:   4.6\n",
      "Average loss at step 3129999:   4.7\n",
      "Average loss at step 3131999:   4.7\n",
      "Average loss at step 3133999:   4.6\n",
      "Average loss at step 3135999:   4.6\n",
      "Average loss at step 3137999:   4.7\n",
      "Average loss at step 3139999:   4.7\n",
      "Average loss at step 3141999:   4.7\n",
      "Average loss at step 3143999:   4.5\n",
      "Average loss at step 3145999:   4.7\n",
      "Average loss at step 3147999:   4.7\n",
      "Average loss at step 3149999:   4.6\n",
      "Average loss at step 3151999:   4.8\n",
      "Average loss at step 3153999:   4.7\n",
      "Average loss at step 3155999:   4.7\n",
      "Average loss at step 3157999:   4.7\n",
      "Average loss at step 3159999:   4.6\n",
      "Average loss at step 3161999:   4.8\n",
      "Average loss at step 3163999:   4.7\n",
      "Average loss at step 3165999:   4.7\n",
      "Average loss at step 3167999:   4.7\n",
      "Average loss at step 3169999:   4.7\n",
      "Average loss at step 3171999:   4.7\n",
      "Average loss at step 3173999:   4.7\n",
      "Average loss at step 3175999:   4.7\n",
      "Average loss at step 3177999:   4.8\n",
      "Average loss at step 3179999:   4.7\n",
      "Average loss at step 3181999:   4.6\n",
      "Average loss at step 3183999:   4.7\n",
      "Average loss at step 3185999:   4.6\n",
      "Average loss at step 3187999:   4.7\n",
      "Average loss at step 3189999:   4.6\n",
      "Average loss at step 3191999:   4.7\n",
      "Average loss at step 3193999:   4.2\n",
      "Average loss at step 3195999:   4.0\n",
      "Average loss at step 3197999:   4.1\n",
      "Average loss at step 3199999:   4.4\n",
      "Average loss at step 3201999:   4.7\n",
      "Average loss at step 3203999:   4.4\n",
      "Average loss at step 3205999:   4.4\n",
      "Average loss at step 3207999:   4.2\n",
      "Average loss at step 3209999:   4.2\n",
      "Average loss at step 3211999:   4.0\n",
      "Average loss at step 3213999:   4.0\n",
      "Average loss at step 3215999:   3.9\n",
      "Average loss at step 3217999:   3.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 3219999:   3.8\n",
      "Average loss at step 3221999:   3.7\n",
      "Average loss at step 3223999:   3.8\n",
      "Average loss at step 3225999:   3.9\n",
      "Average loss at step 3227999:   3.9\n",
      "Average loss at step 3229999:   3.9\n",
      "Average loss at step 3231999:   4.2\n",
      "Average loss at step 3233999:   4.3\n",
      "Average loss at step 3235999:   3.7\n",
      "Average loss at step 3237999:   4.3\n",
      "Average loss at step 3239999:   4.8\n",
      "Average loss at step 3241999:   4.8\n",
      "Average loss at step 3243999:   4.7\n",
      "Average loss at step 3245999:   4.7\n",
      "Average loss at step 3247999:   4.7\n",
      "Average loss at step 3249999:   4.7\n",
      "Average loss at step 3251999:   4.5\n",
      "Average loss at step 3253999:   4.2\n",
      "Average loss at step 3255999:   3.8\n",
      "Average loss at step 3257999:   3.9\n",
      "Average loss at step 3259999:   3.9\n",
      "Average loss at step 3261999:   4.0\n",
      "Average loss at step 3263999:   4.0\n",
      "Average loss at step 3265999:   4.5\n",
      "Average loss at step 3267999:   4.6\n",
      "Average loss at step 3269999:   4.0\n",
      "Average loss at step 3271999:   3.6\n",
      "Average loss at step 3273999:   4.9\n",
      "Average loss at step 3275999:   4.7\n",
      "Average loss at step 3277999:   4.6\n",
      "Average loss at step 3279999:   4.6\n",
      "Average loss at step 3281999:   4.6\n",
      "Average loss at step 3283999:   4.6\n",
      "Average loss at step 3285999:   4.1\n",
      "Average loss at step 3287999:   3.9\n",
      "Average loss at step 3289999:   3.6\n",
      "Average loss at step 3291999:   3.8\n",
      "Average loss at step 3293999:   4.0\n",
      "Average loss at step 3295999:   3.7\n",
      "Average loss at step 3297999:   3.7\n",
      "Average loss at step 3299999:   3.7\n",
      "Average loss at step 3301999:   4.7\n",
      "Average loss at step 3303999:   4.7\n",
      "Average loss at step 3305999:   4.7\n",
      "Average loss at step 3307999:   3.8\n",
      "Average loss at step 3309999:   3.9\n",
      "Average loss at step 3311999:   3.8\n",
      "Average loss at step 3313999:   3.7\n",
      "Average loss at step 3315999:   3.5\n",
      "Average loss at step 3317999:   4.4\n",
      "Average loss at step 3319999:   4.3\n",
      "Average loss at step 3321999:   3.6\n",
      "Average loss at step 3323999:   3.7\n",
      "Average loss at step 3325999:   3.7\n",
      "Average loss at step 3327999:   3.7\n",
      "Average loss at step 3329999:   3.8\n",
      "Average loss at step 3331999:   4.3\n",
      "Average loss at step 3333999:   4.5\n",
      "Average loss at step 3335999:   3.7\n",
      "Average loss at step 3337999:   3.7\n",
      "Average loss at step 3339999:   3.9\n",
      "Average loss at step 3341999:   4.6\n",
      "Average loss at step 3343999:   3.8\n",
      "Average loss at step 3345999:   4.8\n",
      "Average loss at step 3347999:   4.7\n",
      "Average loss at step 3349999:   4.6\n",
      "Average loss at step 3351999:   3.7\n",
      "Average loss at step 3353999:   4.4\n",
      "Average loss at step 3355999:   4.5\n",
      "Average loss at step 3357999:   3.8\n",
      "Average loss at step 3359999:   4.7\n",
      "Average loss at step 3361999:   4.7\n",
      "Average loss at step 3363999:   4.7\n",
      "Average loss at step 3365999:   4.7\n",
      "Average loss at step 3367999:   4.7\n",
      "Average loss at step 3369999:   4.8\n",
      "Average loss at step 3371999:   4.7\n",
      "Average loss at step 3373999:   4.7\n",
      "Average loss at step 3375999:   4.8\n",
      "Average loss at step 3377999:   4.7\n",
      "Average loss at step 3379999:   4.6\n",
      "Average loss at step 3381999:   4.6\n",
      "Average loss at step 3383999:   4.7\n",
      "Average loss at step 3385999:   4.6\n",
      "Average loss at step 3387999:   4.7\n",
      "Average loss at step 3389999:   4.7\n",
      "Average loss at step 3391999:   4.7\n",
      "Average loss at step 3393999:   4.5\n",
      "Average loss at step 3395999:   4.6\n",
      "Average loss at step 3397999:   4.6\n",
      "Average loss at step 3399999:   4.7\n",
      "Average loss at step 3401999:   4.6\n",
      "Average loss at step 3403999:   4.6\n",
      "Average loss at step 3405999:   4.7\n",
      "Average loss at step 3407999:   4.7\n",
      "Average loss at step 3409999:   4.7\n",
      "Average loss at step 3411999:   4.8\n",
      "Average loss at step 3413999:   4.7\n",
      "Average loss at step 3415999:   4.6\n",
      "Average loss at step 3417999:   4.5\n",
      "Average loss at step 3419999:   4.6\n",
      "Average loss at step 3421999:   4.7\n",
      "Average loss at step 3423999:   4.7\n",
      "Average loss at step 3425999:   4.7\n",
      "Average loss at step 3427999:   4.7\n",
      "Average loss at step 3429999:   4.7\n",
      "Average loss at step 3431999:   4.7\n",
      "Average loss at step 3433999:   4.6\n",
      "Average loss at step 3435999:   4.7\n",
      "Average loss at step 3437999:   4.7\n",
      "Average loss at step 3439999:   4.7\n",
      "Average loss at step 3441999:   4.7\n",
      "Average loss at step 3443999:   4.7\n",
      "Average loss at step 3445999:   4.7\n",
      "Average loss at step 3447999:   4.6\n",
      "Average loss at step 3449999:   4.7\n",
      "Average loss at step 3451999:   4.8\n",
      "Average loss at step 3453999:   4.6\n",
      "Average loss at step 3455999:   4.5\n",
      "Average loss at step 3457999:   4.6\n",
      "Average loss at step 3459999:   4.8\n",
      "Average loss at step 3461999:   4.3\n",
      "Average loss at step 3463999:   4.0\n",
      "Average loss at step 3465999:   4.0\n",
      "Average loss at step 3467999:   4.1\n",
      "Average loss at step 3469999:   3.9\n",
      "Average loss at step 3471999:   4.1\n",
      "Average loss at step 3473999:   3.9\n",
      "Average loss at step 3475999:   4.6\n",
      "Average loss at step 3477999:   4.7\n",
      "Average loss at step 3479999:   3.7\n",
      "Average loss at step 3481999:   4.0\n",
      "Average loss at step 3483999:   4.4\n",
      "Average loss at step 3485999:   4.3\n",
      "Average loss at step 3487999:   4.7\n",
      "Average loss at step 3489999:   4.1\n",
      "Average loss at step 3491999:   3.9\n",
      "Average loss at step 3493999:   4.0\n",
      "Average loss at step 3495999:   4.0\n",
      "Average loss at step 3497999:   4.1\n",
      "Average loss at step 3499999:   3.9\n",
      "Average loss at step 3501999:   4.4\n",
      "Average loss at step 3503999:   4.7\n",
      "Average loss at step 3505999:   4.7\n",
      "Average loss at step 3507999:   4.7\n",
      "Average loss at step 3509999:   4.7\n",
      "Average loss at step 3511999:   4.7\n",
      "Average loss at step 3513999:   4.7\n",
      "Average loss at step 3515999:   4.8\n",
      "Average loss at step 3517999:   4.7\n",
      "Average loss at step 3519999:   4.0\n",
      "Average loss at step 3521999:   3.8\n",
      "Average loss at step 3523999:   3.9\n",
      "Average loss at step 3525999:   3.8\n",
      "Average loss at step 3527999:   3.7\n",
      "Average loss at step 3529999:   3.8\n",
      "Average loss at step 3531999:   3.7\n",
      "Average loss at step 3533999:   3.6\n",
      "Average loss at step 3535999:   3.6\n",
      "Average loss at step 3537999:   3.7\n",
      "Average loss at step 3539999:   3.7\n",
      "Average loss at step 3541999:   3.6\n",
      "Average loss at step 3543999:   3.6\n",
      "Average loss at step 3545999:   3.8\n",
      "Average loss at step 3547999:   3.9\n",
      "Average loss at step 3549999:   3.9\n",
      "Average loss at step 3551999:   3.8\n",
      "Average loss at step 3553999:   3.9\n",
      "Average loss at step 3555999:   3.8\n",
      "Average loss at step 3557999:   4.2\n",
      "Average loss at step 3559999:   4.1\n",
      "Average loss at step 3561999:   4.2\n",
      "Average loss at step 3563999:   4.1\n",
      "Average loss at step 3565999:   3.8\n",
      "Average loss at step 3567999:   3.8\n",
      "Average loss at step 3569999:   4.1\n",
      "Average loss at step 3571999:   3.7\n",
      "Average loss at step 3573999:   3.9\n",
      "Average loss at step 3575999:   3.9\n",
      "Average loss at step 3577999:   3.9\n",
      "Average loss at step 3579999:   4.0\n",
      "Average loss at step 3581999:   3.9\n",
      "Average loss at step 3583999:   4.2\n",
      "Average loss at step 3585999:   4.1\n",
      "Average loss at step 3587999:   3.7\n",
      "Average loss at step 3589999:   4.0\n",
      "Average loss at step 3591999:   3.7\n",
      "Average loss at step 3593999:   4.0\n",
      "Average loss at step 3595999:   3.8\n",
      "Average loss at step 3597999:   3.7\n",
      "Average loss at step 3599999:   3.8\n",
      "Average loss at step 3601999:   3.7\n",
      "Average loss at step 3603999:   3.7\n",
      "Average loss at step 3605999:   3.8\n",
      "Average loss at step 3607999:   3.9\n",
      "Average loss at step 3609999:   3.8\n",
      "Average loss at step 3611999:   3.8\n",
      "Average loss at step 3613999:   3.7\n",
      "Average loss at step 3615999:   3.8\n",
      "Average loss at step 3617999:   4.0\n",
      "Average loss at step 3619999:   3.8\n",
      "Average loss at step 3621999:   3.6\n",
      "Average loss at step 3623999:   3.7\n",
      "Average loss at step 3625999:   3.7\n",
      "Average loss at step 3627999:   3.6\n",
      "Average loss at step 3629999:   3.6\n",
      "Average loss at step 3631999:   3.7\n",
      "Average loss at step 3633999:   3.7\n",
      "Average loss at step 3635999:   3.7\n",
      "Average loss at step 3637999:   3.8\n",
      "Average loss at step 3639999:   3.7\n",
      "Average loss at step 3641999:   3.6\n",
      "Average loss at step 3643999:   3.9\n",
      "Average loss at step 3645999:   3.7\n",
      "Average loss at step 3647999:   3.6\n",
      "Average loss at step 3649999:   3.7\n",
      "Average loss at step 3651999:   3.6\n",
      "Average loss at step 3653999:   3.6\n",
      "Average loss at step 3655999:   3.7\n",
      "Average loss at step 3657999:   3.7\n",
      "Average loss at step 3659999:   3.9\n",
      "Average loss at step 3661999:   3.8\n",
      "Average loss at step 3663999:   3.7\n",
      "Average loss at step 3665999:   3.6\n",
      "Average loss at step 3667999:   3.7\n",
      "Average loss at step 3669999:   3.6\n",
      "Average loss at step 3671999:   3.6\n",
      "Average loss at step 3673999:   3.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 3675999:   3.6\n",
      "Average loss at step 3677999:   3.7\n",
      "Average loss at step 3679999:   3.6\n",
      "Average loss at step 3681999:   3.5\n",
      "Average loss at step 3683999:   3.7\n",
      "Average loss at step 3685999:   3.6\n",
      "Average loss at step 3687999:   3.6\n",
      "Average loss at step 3689999:   3.8\n",
      "Average loss at step 3691999:   3.9\n",
      "Average loss at step 3693999:   3.8\n",
      "Average loss at step 3695999:   3.7\n",
      "Average loss at step 3697999:   3.8\n",
      "Average loss at step 3699999:   3.6\n",
      "Average loss at step 3701999:   3.7\n",
      "Average loss at step 3703999:   3.6\n",
      "Average loss at step 3705999:   3.7\n",
      "Average loss at step 3707999:   3.8\n",
      "Average loss at step 3709999:   3.7\n",
      "Average loss at step 3711999:   3.7\n",
      "Average loss at step 3713999:   3.6\n",
      "Average loss at step 3715999:   4.1\n",
      "Average loss at step 3717999:   3.7\n",
      "Average loss at step 3719999:   3.5\n",
      "Average loss at step 3721999:   3.6\n",
      "Average loss at step 3723999:   3.5\n",
      "Average loss at step 3725999:   3.7\n",
      "Average loss at step 3727999:   3.6\n",
      "Average loss at step 3729999:   3.5\n",
      "Average loss at step 3731999:   3.5\n",
      "Average loss at step 3733999:   3.8\n",
      "Average loss at step 3735999:   3.6\n",
      "Average loss at step 3737999:   3.6\n",
      "Average loss at step 3739999:   3.9\n",
      "Average loss at step 3741999:   3.6\n",
      "Average loss at step 3743999:   3.5\n",
      "Average loss at step 3745999:   3.8\n",
      "Average loss at step 3747999:   3.7\n",
      "Average loss at step 3749999:   3.5\n",
      "Average loss at step 3751999:   3.7\n",
      "Average loss at step 3753999:   3.7\n",
      "Average loss at step 3755999:   3.6\n",
      "Average loss at step 3757999:   3.5\n",
      "Average loss at step 3759999:   3.5\n",
      "Average loss at step 3761999:   3.6\n",
      "Average loss at step 3763999:   3.5\n",
      "Average loss at step 3765999:   3.9\n",
      "Average loss at step 3767999:   4.9\n",
      "Average loss at step 3769999:   4.8\n",
      "Average loss at step 3771999:   4.8\n",
      "Average loss at step 3773999:   4.7\n",
      "Average loss at step 3775999:   4.7\n",
      "Average loss at step 3777999:   4.7\n",
      "Average loss at step 3779999:   4.7\n",
      "Average loss at step 3781999:   4.6\n",
      "Average loss at step 3783999:   3.5\n",
      "Average loss at step 3785999:   3.5\n",
      "Average loss at step 3787999:   3.6\n",
      "Average loss at step 3789999:   3.6\n",
      "Average loss at step 3791999:   3.5\n",
      "Average loss at step 3793999:   3.6\n",
      "Average loss at step 3795999:   3.5\n",
      "Average loss at step 3797999:   3.6\n",
      "Average loss at step 3799999:   3.5\n",
      "Average loss at step 3801999:   3.6\n",
      "Average loss at step 3803999:   3.5\n",
      "Average loss at step 3805999:   3.5\n",
      "Average loss at step 3807999:   3.5\n",
      "Average loss at step 3809999:   3.7\n",
      "Average loss at step 3811999:   3.4\n",
      "Average loss at step 3813999:   3.7\n",
      "Average loss at step 3815999:   3.6\n",
      "Average loss at step 3817999:   3.4\n",
      "Average loss at step 3819999:   3.5\n",
      "Average loss at step 3821999:   3.7\n",
      "Average loss at step 3823999:   3.5\n",
      "Average loss at step 3825999:   3.6\n",
      "Average loss at step 3827999:   3.6\n",
      "Average loss at step 3829999:   3.6\n",
      "Average loss at step 3831999:   3.5\n",
      "Average loss at step 3833999:   3.5\n",
      "Average loss at step 3835999:   3.6\n",
      "Average loss at step 3837999:   3.7\n",
      "Average loss at step 3839999:   3.5\n",
      "Average loss at step 3841999:   3.5\n",
      "Average loss at step 3843999:   3.6\n",
      "Average loss at step 3845999:   3.6\n",
      "Average loss at step 3847999:   3.6\n",
      "Average loss at step 3849999:   3.6\n",
      "Average loss at step 3851999:   3.7\n",
      "Average loss at step 3853999:   3.5\n",
      "Average loss at step 3855999:   3.6\n",
      "Average loss at step 3857999:   3.6\n",
      "Average loss at step 3859999:   3.7\n",
      "Average loss at step 3861999:   3.8\n"
     ]
    }
   ],
   "source": [
    "model = SkipGramModel(vocabulary_size, embedding_size, batch_size, num_sampled, learning_rate)\n",
    "model.build_graph()\n",
    "batch_gen = generate_batch(data, batch_size, skip_window)\n",
    "train_model(model, batch_gen, num_train_steps, log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
